{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the memory usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 1603.49 Mb to 467.68 Mb (70.8% reduction)\n",
      "Mem. usage decreased from 571.30 Mb to 166.63 Mb (70.8% reduction)\n",
      "Mem. usage decreased from 368.96 Mb to 107.61 Mb (70.8% reduction)\n",
      "Mem. usage decreased from 173.23 Mb to 50.53 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "# read data from file:\n",
    "train_set0 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/train_set0.csv')\n",
    "train_set0 = reduce_mem_usage(train_set0)\n",
    "train_set1 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/train_set1.csv')\n",
    "train_set1 = reduce_mem_usage(train_set1)\n",
    "train_set2 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/train_set2.csv')\n",
    "train_set2 = reduce_mem_usage(train_set2)\n",
    "train_set3 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/train_set3.csv')\n",
    "train_set3 = reduce_mem_usage(train_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11676263, 18), (4160090, 18), (2686678, 18), (1261421, 18))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set0.shape, train_set1.shape, train_set2.shape, train_set3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>sealev</th>\n",
       "      <th>dewtemp</th>\n",
       "      <th>windsp</th>\n",
       "      <th>North</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>nowind</th>\n",
       "      <th>dewair</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 18:00:00</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.425537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>68.219910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 19:00:00</td>\n",
       "      <td>0.706055</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81.423767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 20:00:00</td>\n",
       "      <td>0.740723</td>\n",
       "      <td>0.595703</td>\n",
       "      <td>0.881836</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158325</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.020416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 21:00:00</td>\n",
       "      <td>0.763184</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>70.620689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 22:00:00</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>74.021523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  building_id  primary_use  square_feet            timestamp  \\\n",
       "0        0            0            0     0.008171  2016-05-20 18:00:00   \n",
       "1        0            0            0     0.008171  2016-05-20 19:00:00   \n",
       "2        0            0            0     0.008171  2016-05-20 20:00:00   \n",
       "3        0            0            0     0.008171  2016-05-20 21:00:00   \n",
       "4        0            0            0     0.008171  2016-05-20 22:00:00   \n",
       "\n",
       "    airtemp    sealev   dewtemp    windsp  North  West  South  nowind  \\\n",
       "0  0.698242  0.606934  0.863770  0.425537    0.0   0.0    0.0     0.0   \n",
       "1  0.706055  0.597168  0.873535  0.235596    0.0   0.0    0.0     0.0   \n",
       "2  0.740723  0.595703  0.881836  0.148804    0.0   0.0    0.0     0.0   \n",
       "3  0.763184  0.589844  0.873535  0.210693    1.0   0.0    0.0     0.0   \n",
       "4  0.734375  0.584961  0.891602  0.235596    1.0   0.0    0.0     0.0   \n",
       "\n",
       "     dewair  month  weekday  hour  meter_reading  \n",
       "0  0.120483    5.0      4.0  18.0      68.219910  \n",
       "1  0.120483    5.0      4.0  19.0      81.423767  \n",
       "2  0.158325    5.0      4.0  20.0      70.020416  \n",
       "3  0.196167    5.0      4.0  21.0      70.620689  \n",
       "4  0.139404    5.0      4.0  22.0      74.021523  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to rescale the meter_reading:\n",
    "rob_0 = RobustScaler()\n",
    "mm_0 = MinMaxScaler()\n",
    "rob_1 = RobustScaler()\n",
    "mm_1 = MinMaxScaler()\n",
    "rob_2 = RobustScaler()\n",
    "mm_2 = MinMaxScaler()\n",
    "rob_3 = RobustScaler()\n",
    "mm_3 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data scaling for y: log1p --> RobustScaler --> MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set0.meter_reading = mm_0.fit_transform(rob_0.fit_transform(np.log1p(train_set0.meter_reading).values.reshape(-1,1)))\n",
    "train_set1.meter_reading = mm_1.fit_transform(rob_1.fit_transform(np.log1p(train_set1.meter_reading).values.reshape(-1,1)))\n",
    "train_set2.meter_reading = mm_2.fit_transform(rob_2.fit_transform(np.log1p(train_set2.meter_reading).values.reshape(-1,1)))\n",
    "train_set3.meter_reading = mm_3.fit_transform(rob_3.fit_transform(np.log1p(train_set3.meter_reading).values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mm_0, open('mm_0.pkl', 'wb'))\n",
    "pickle.dump(rob_0, open('rob_0.pkl', 'wb'))\n",
    "pickle.dump(mm_1, open('mm_1.pkl', 'wb'))\n",
    "pickle.dump(rob_1, open('rob_1.pkl', 'wb'))\n",
    "pickle.dump(mm_2, open('mm_2.pkl', 'wb'))\n",
    "pickle.dump(rob_2, open('rob_2.pkl', 'wb'))\n",
    "pickle.dump(mm_3, open('mm_3.pkl', 'wb'))\n",
    "pickle.dump(rob_3, open('rob_3.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x184bc6ea4a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set0.meter_reading.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>sealev</th>\n",
       "      <th>dewtemp</th>\n",
       "      <th>windsp</th>\n",
       "      <th>North</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>nowind</th>\n",
       "      <th>dewair</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 18:00:00</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.425537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.375416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 19:00:00</td>\n",
       "      <td>0.706055</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.390884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 20:00:00</td>\n",
       "      <td>0.740723</td>\n",
       "      <td>0.595703</td>\n",
       "      <td>0.881836</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158325</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.377692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 21:00:00</td>\n",
       "      <td>0.763184</td>\n",
       "      <td>0.589844</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196167</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.378437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2016-05-20 22:00:00</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.382547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  building_id  primary_use  square_feet            timestamp  \\\n",
       "0        0            0            0     0.008171  2016-05-20 18:00:00   \n",
       "1        0            0            0     0.008171  2016-05-20 19:00:00   \n",
       "2        0            0            0     0.008171  2016-05-20 20:00:00   \n",
       "3        0            0            0     0.008171  2016-05-20 21:00:00   \n",
       "4        0            0            0     0.008171  2016-05-20 22:00:00   \n",
       "\n",
       "    airtemp    sealev   dewtemp    windsp  North  West  South  nowind  \\\n",
       "0  0.698242  0.606934  0.863770  0.425537    0.0   0.0    0.0     0.0   \n",
       "1  0.706055  0.597168  0.873535  0.235596    0.0   0.0    0.0     0.0   \n",
       "2  0.740723  0.595703  0.881836  0.148804    0.0   0.0    0.0     0.0   \n",
       "3  0.763184  0.589844  0.873535  0.210693    1.0   0.0    0.0     0.0   \n",
       "4  0.734375  0.584961  0.891602  0.235596    1.0   0.0    0.0     0.0   \n",
       "\n",
       "     dewair  month  weekday  hour  meter_reading  \n",
       "0  0.120483    5.0      4.0  18.0       0.375416  \n",
       "1  0.120483    5.0      4.0  19.0       0.390884  \n",
       "2  0.158325    5.0      4.0  20.0       0.377692  \n",
       "3  0.196167    5.0      4.0  21.0       0.378437  \n",
       "4  0.139404    5.0      4.0  22.0       0.382547  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1413, 498, 324, 145)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set0.building_id.nunique(), train_set1.building_id.nunique(), train_set2.building_id.nunique(), train_set3.building_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network design:\n",
    "1. Each has 6 inputs, 5 of them are inputs of embedding layers, the rest is numeric input.\n",
    "2. Categorical embedding for features: building_id, month, hour, etc .\n",
    "3. Output of them are concatenated as input of main network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network structure and parameters optimization\n",
    "based on the design of the network, I will search for \n",
    "1. best number of layers, \n",
    "2. activation, \n",
    "3. learning rate, \n",
    "4. number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data for search\n",
    "due to the hardware limitation of laptop, I will use a small size of data from training data in my search to improve search efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1/10 data from test_set0 as search_set\n",
    "split_forSearch = StratifiedShuffleSplit(n_splits=1, test_size = 0.1, random_state=100)\n",
    "for train_index, test_index in split_forSearch.split(train_set0, train_set0.building_id):\n",
    "    strat_search_set = train_set0.iloc[test_index]\n",
    "# split search_set:\n",
    "split_Search = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=100)\n",
    "for train_index, test_index in split_Search.split(strat_search_set, strat_search_set.building_id):\n",
    "    search_train_set = strat_search_set.iloc[train_index]\n",
    "    search_test_set = strat_search_set.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11676263, 18), (934101, 18), (233526, 18))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set0.shape, search_train_set.shape, search_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_srch = [search_train_set.building_id.values, search_train_set.primary_use.values, \n",
    "      search_train_set.month.values, search_train_set.weekday.values, search_train_set.hour.values, \n",
    "      search_train_set.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y_srch = search_train_set.meter_reading.values\n",
    "X_test_srch = [search_test_set.building_id.values, search_test_set.primary_use.values, \n",
    "      search_test_set.month.values, search_test_set.weekday.values, search_test_set.hour.values, \n",
    "      search_test_set.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y_test_srch = search_test_set.meter_reading.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1139, 1186,  331, ..., 1356, 1393,  637], dtype=int16),\n",
       " array([6, 4, 0, ..., 0, 1, 0], dtype=int8),\n",
       " array([5., 9., 6., ..., 8., 4., 9.], dtype=float16),\n",
       " array([5., 4., 3., ..., 5., 5., 4.], dtype=float16),\n",
       " array([14.,  4., 23., ...,  7.,  9., 10.], dtype=float16),\n",
       " array([[6.000e+00, 3.845e-01, 5.972e-01, ..., 5.000e+00, 5.000e+00,\n",
       "         1.400e+01],\n",
       "        [4.000e+00, 1.792e-01, 6.050e-01, ..., 9.000e+00, 4.000e+00,\n",
       "         4.000e+00],\n",
       "        [0.000e+00, 3.298e-01, 7.202e-01, ..., 6.000e+00, 3.000e+00,\n",
       "         2.300e+01],\n",
       "        ...,\n",
       "        [0.000e+00, 1.040e-01, 5.830e-01, ..., 8.000e+00, 5.000e+00,\n",
       "         7.000e+00],\n",
       "        [1.000e+00, 1.733e-01, 4.468e-01, ..., 4.000e+00, 5.000e+00,\n",
       "         9.000e+00],\n",
       "        [0.000e+00, 4.467e-03, 5.767e-01, ..., 9.000e+00, 4.000e+00,\n",
       "         1.000e+01]], dtype=float16)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_srch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization for number of layers for main layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_main_layers: 3 \n",
      "test_rmse_score: 0.043319277 \n",
      "trainingMSE: [0.009893378128833202, 0.003332816328923974, 0.002989253591142015, 0.00283732685851579, 0.0027037841369748883, 0.002624461611547396, 0.002568561064604196, 0.002514130400351005, 0.002485008112157326, 0.002452244454645007, 0.002424419814514013, 0.002404790903181214, 0.002382205432957424, 0.002349218228289913, 0.002324607425408289, 0.0022993327014002233, 0.002291416039088134, 0.002287998658085317, 0.0022748965132983116, 0.0022554433438659234, 0.002234434313463771, 0.0022457728041247334, 0.002227759183223973, 0.002217059113715693, 0.002223296324815341, 0.0022128714751745793, 0.0022023780870037302, 0.002193375331780781, 0.0021869337748193756, 0.0021814615308745748, 0.0021834739594804036, 0.0021786169431410496, 0.002170805390094027, 0.0021552052700971676, 0.002168113967587974, 0.0021612184957790965, 0.0021675024719335165, 0.002153787755699229, 0.002146614511092832, 0.002142324804787594, 0.0021385091385012346, 0.002139756439993299, 0.0021332583811283, 0.002147907513956031, 0.002142275888526291, 0.002135030320457127, 0.002136144212705154, 0.002122777349047386, 0.0021251018775435724, 0.002126433984136601] \n",
      "\n",
      "num_main_layers: 4 \n",
      "test_rmse_score: 0.05202029 \n",
      "trainingMSE: [0.01650512536459496, 0.0033967501675287036, 0.0028989097661763106, 0.002657313786297841, 0.002522281879259719, 0.0024427105444366055, 0.0023853824743155262, 0.0023469730314649487, 0.0023261841556126246, 0.0022744711960853117, 0.0022540348444036237, 0.002234276141432467, 0.0022150587387424355, 0.002199953667449315, 0.0021855750787512854, 0.0021687650476253846, 0.0021671488246752134, 0.0021470714368143663, 0.002138449430277094, 0.002134318589903227, 0.002128447651647951, 0.0021236539049390786, 0.0021144768555717364, 0.002099408621643904, 0.0020970508779255726, 0.0020917202577865252, 0.002085967724264791, 0.0020757667023191587, 0.002081179791597945, 0.0020700567588314593, 0.002059926972860721, 0.0020525122337437464, 0.0020505556103612385, 0.002047179147092822, 0.0020503764027234523, 0.0020491454877460593, 0.0020471016371404077, 0.0020365634222577304, 0.0020404004948136436, 0.0020336659469731844, 0.002030224558620646, 0.0020252635075205193, 0.002028459433699568, 0.0020249516441825147, 0.002021013508508119, 0.0020174606779976316, 0.002006785720745294, 0.0020086427512525013, 0.0020151685394821663, 0.002013193235041201] \n",
      "\n",
      "num_main_layers: 5 \n",
      "test_rmse_score: 0.042215783 \n",
      "trainingMSE: [0.015046462522065374, 0.003517989044554499, 0.002983825847365785, 0.0027409783015853767, 0.002613395768473989, 0.002524445800212774, 0.0024502130664512236, 0.0023868114637334054, 0.0023501264460144946, 0.0023185837741150814, 0.0022823057382138673, 0.002262961729394113, 0.002244219839413279, 0.0022228179830414375, 0.0022081086897029405, 0.002191971823011564, 0.002177962233108296, 0.002156716877725685, 0.002153071013870523, 0.0021436202620371565, 0.002138805658801302, 0.0021292580879583287, 0.002115147170420338, 0.0021143161898895826, 0.0021115341137290604, 0.00210464434236847, 0.0020975915684057983, 0.002081124173282208, 0.0020942344459913393, 0.0020736356508434936, 0.0020830700384178555, 0.002072304025565864, 0.002058076456451056, 0.002066955612862018, 0.0020626706509308964, 0.0020543769430259005, 0.002053176527282541, 0.002053196817312436, 0.002052404526233679, 0.002040094221452434, 0.0020327447788934224, 0.0020276333633228558, 0.002031165381512979, 0.002026257463831935, 0.0020213017064079674, 0.002024165304322045, 0.0020125502905142777, 0.0020274511066532813, 0.0020219153265913243, 0.002012945168472059] \n",
      "\n",
      "num_main_layers: 6 \n",
      "test_rmse_score: 0.039043464 \n",
      "trainingMSE: [0.010107002810021786, 0.0032073707206064384, 0.0027914056041711305, 0.0025601550991808503, 0.0024419971870947334, 0.0023619414644345687, 0.002328570409410631, 0.002278371781523261, 0.002245775983606723, 0.002218486841992947, 0.002193585467950994, 0.002179326384914096, 0.0021583442857177667, 0.0021402790228692748, 0.002124317662018548, 0.0021157845251863843, 0.002088162564081711, 0.0020850251362406463, 0.002070891865739384, 0.002055184176384556, 0.002027895828408113, 0.0020227690503195985, 0.002024566272480361, 0.0020108191454943185, 0.0019909011218562215, 0.001980468098468045, 0.0019795613852390845, 0.001979860036093045, 0.001976586043028587, 0.0019636261779538743, 0.0019435917393749388, 0.0019558229786720924, 0.0019461538753531074, 0.0019386936640237837, 0.001939900515225541, 0.0019243208647968329, 0.001923756381620133, 0.001926062159878122, 0.0019230194170996417, 0.0019138130538611472, 0.0019095902216950183, 0.0019017881029541463, 0.0019030666529749893, 0.001897423367642621, 0.001887206320803239, 0.0018855616024396385, 0.0018857604844032814, 0.0018833096800250158, 0.0018812044783065968, 0.0018937007547022659] \n",
      "\n",
      "num_main_layers: 7 \n",
      "test_rmse_score: 0.049202614 \n",
      "trainingMSE: [0.013718805430868003, 0.003463059552807626, 0.0030314956015692, 0.0028138171129238098, 0.0027097793285701163, 0.0025985918308968035, 0.0025137422396547893, 0.0024498294593348854, 0.002402222757230665, 0.002368013535630497, 0.0023272774762555333, 0.0023099076297804742, 0.002268666658368169, 0.0022493948775783247, 0.002223434781477109, 0.0022074233349863256, 0.0021954543727617046, 0.00218109592699167, 0.0021756454711260535, 0.0021494766047533477, 0.0021336288413461822, 0.002127872987309703, 0.0021272346032314158, 0.0021121805839980964, 0.0021048488310095224, 0.0020971423156587034, 0.0020929112630233577, 0.0020733133091772314, 0.002071440714562855, 0.0020614180161317485, 0.002065184431200957, 0.0020477579774477945, 0.002046755662655581, 0.0020430895467046053, 0.0020345428775872137, 0.002031683796517264, 0.0020287762825405144, 0.0020161650644223124, 0.002019855057549109, 0.002008628922343694, 0.0020167363460692448, 0.0020116045619519613, 0.0019972056787448994, 0.001994010648682082, 0.001997329867157176, 0.0019834242833808545, 0.001974279426609033, 0.001970490653070977, 0.0019711261286122737, 0.001966261681281009] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_layers = 1 \n",
    "while num_layers < 6: \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, 50, name = 'building_id_emb')(input_building_id)\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(20, activation='relu')(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "#    building_id_emb = layers.Dropout(0.1)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation='relu')(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, 8, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "#    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(4, activation='relu')(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "#    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation='relu')(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation='relu')(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, 8, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation='relu')(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    current_layer = 0 \n",
    "    while current_layer < num_layers: \n",
    "        main_Layers = layers.Dense(50, activation='relu')(main_Layers)\n",
    "        main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "        current_layer+=1 \n",
    "    \n",
    "    main_Layers = layers.Dense(20, activation='relu')(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation='relu')(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001,beta_1=0.9,beta_2=0.999, epsilon=1e-08), \n",
    "                  loss='mse' # tf.keras.losses.mean_squared_error\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    history = model.fit(X_srch, y_srch, epochs=50\n",
    "              , batch_size=64\n",
    "              , verbose=0\n",
    "             )\n",
    "    \n",
    "    test_pred = model.predict(X_test_srch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_srch, test_pred))\n",
    "    print('num_main_layers:',(num_layers+2),'\\ntest_rmse_score:',\n",
    "          test_rmse,'\\ntrainingMSE:',history.history.get('loss'),'\\n') \n",
    "    num_layers +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 6 main layers for this network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation: relu \n",
      "test_rmse_score: 0.102770016 \n",
      "trainingMSE: [0.011147059708640147, 0.003358485337275134, 0.0029429113236418233, 0.0027257701204925367, 0.0025971752100637084, 0.0025003659997509093, 0.0024499420514320826, 0.0024051647928598208, 0.002371382188151805, 0.0023385558232208773, 0.0022967880933195007, 0.002282444670275494, 0.0022615779794734705, 0.0022305388789500102, 0.002220034948816495, 0.0022084448189192704, 0.002188725276605423, 0.002181484669291406, 0.0021570510842488827, 0.0021536383847215157, 0.0021413787215563656, 0.0021400112482792993, 0.0021190900188549763, 0.002118499205061958, 0.0020997507699717865, 0.002098732975151943, 0.002095273259730199, 0.002083405537493529, 0.002067567318217372, 0.002073322985799353] \n",
      "\n",
      "activation: tanh \n",
      "test_rmse_score: 0.044920884 \n",
      "trainingMSE: [0.006845265448053675, 0.003210480836428016, 0.0030601517432889097, 0.003007285532997659, 0.0029233139257168364, 0.0028318823897634368, 0.002844542812161567, 0.002807555529748033, 0.00273515670926792, 0.0027282866719689756, 0.0027609524326051745, 0.0027012717578739536, 0.0026685574890110324, 0.0026343135383702864, 0.0026325777993287253, 0.002588246003126933, 0.002567439936173955, 0.0025548087359317795, 0.002520404605199026, 0.0025030687810867844, 0.0024649680318238765, 0.0024461310453770513, 0.002436860191490813, 0.002437508697475176, 0.002444461380171652, 0.0024502515499573107, 0.00243192042276112, 0.002441704483986357, 0.002422589647255615, 0.0024047677873384743] \n",
      "\n",
      "activation: sigmoid \n",
      "test_rmse_score: 0.03969129 \n",
      "trainingMSE: [0.004778648715834748, 0.002716376421557226, 0.002503934621159977, 0.0023938334612529197, 0.002324769483566067, 0.002273332548736089, 0.0022305609802798576, 0.002211235042868961, 0.0021707927634772835, 0.002159576807712302, 0.0021407552686913676, 0.0021152393975695195, 0.0020890031011213607, 0.0020802539300105033, 0.0020664291698503424, 0.00204823569294788, 0.0020447738219725115, 0.002033669510623954, 0.0020268040789204584, 0.0020169513498826995, 0.0019962634910278888, 0.001997605040619884, 0.001989089949907398, 0.0019816659287067704, 0.0019745121550056592, 0.001969921099313836, 0.0019688996078239362, 0.001955936568846277, 0.0019582563340047967, 0.001946572357681448] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "actvs = ['relu','tanh','sigmoid']\n",
    "for each in actvs:\n",
    "    actv = each\n",
    "    alpha = 0.001\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, 50, name = 'building_id_emb')(input_building_id)\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(20, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "#    building_id_emb = layers.Dropout(0.1)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, 8, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "#    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(4, activation=actv)(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "#    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation=actv)(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation=actv)(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, 8, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation=actv)(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(20, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha,beta_1=0.9,beta_2=0.999, epsilon=1e-08)\n",
    "                  , loss='mse'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    history = model.fit(X_srch, y_srch, epochs=30\n",
    "              , batch_size=64\n",
    "              , verbose=0\n",
    "             )\n",
    "    \n",
    "    test_pred = model.predict(X_test_srch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_srch, test_pred))\n",
    "    print('activation:',actv, '\\ntest_rmse_score:',\n",
    "          test_rmse,'\\ntrainingMSE:',history.history.get('loss'),'\\n') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid activation has better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.0017772481865830723 \n",
      "test_rmse_score: 0.043323014 \n",
      "trainingMSE: [0.004950232482665672, 0.002808475162930746, 0.002614216750170071, 0.0024891067145635932, 0.0024566604057523578, 0.002418945776521353, 0.0023686643091079713, 0.002342214460314863, 0.002304089219594977, 0.0022646056757285424, 0.0022576154980029814, 0.002237038796363131, 0.0022247136379752596, 0.002212667141349662, 0.0022051529290208934, 0.002185207220950333, 0.002186222593932149, 0.0021779108438549485, 0.002172088328408473, 0.0021749149307392452, 0.002159694755919803, 0.002160542526746438, 0.0021510542448434605, 0.0021520852357025328, 0.002143553106038547, 0.002145415555538835, 0.0021398034114044466, 0.0021439914522320396, 0.0021251117114267854, 0.002131463745365881] \n",
      "\n",
      "learning rate: 0.0006493512920406538 \n",
      "test_rmse_score: 0.039335683 \n",
      "trainingMSE: [0.005172501747645421, 0.0027623639166190024, 0.002509303808119185, 0.0023979482831290805, 0.002327532970594698, 0.002278233780381161, 0.0022349387901072788, 0.0021989303165838867, 0.00216183513998694, 0.0021418256747069986, 0.0021315299293992902, 0.002101406223858664, 0.002086716508468111, 0.0020824697453712166, 0.0020597021099095832, 0.0020537662240030096, 0.0020469464013184767, 0.0020297915273054658, 0.002026513738834014, 0.0020271054975768274, 0.002010530347451976, 0.001991906047908545, 0.001995691597718299, 0.001991648286585437, 0.0019705915975125722, 0.0019711495849333233, 0.0019684061604681273, 0.001961311624315641, 0.001947270195030232, 0.0019549783164763187] \n",
      "\n",
      "learning rate: 0.0009154481832542021 \n",
      "test_rmse_score: 0.03976514 \n",
      "trainingMSE: [0.005339090521524834, 0.0027348866358864556, 0.0024997687044658263, 0.0023721912277105033, 0.002306260333118447, 0.002232320110584868, 0.0021984045935370196, 0.002168323232615764, 0.002142017448070809, 0.002122132298277666, 0.0021051366290859496, 0.002088061954934267, 0.002071411089041016, 0.0020623280231468187, 0.002046395705202679, 0.002029494109811944, 0.0020334236880450406, 0.002019996964324862, 0.0020125065634259923, 0.00199447366611047, 0.001991869972743439, 0.0019853182969354847, 0.0019656576778289154, 0.001971680833492927, 0.001962473410011779, 0.001959094181755184, 0.0019452165219968176, 0.0019467541419154449, 0.0019351977240608814, 0.0019293854293872814] \n",
      "\n",
      "learning rate: 0.0004996435786026579 \n",
      "test_rmse_score: 0.03886035 \n",
      "trainingMSE: [0.005811752036389668, 0.0027500060436323457, 0.0025028785743378985, 0.0023779684405689622, 0.0023095508476574495, 0.0022547446708036456, 0.0022263588119905094, 0.002199644063155503, 0.0021526238212503028, 0.0021348042021373946, 0.002117122688825108, 0.0020917468723165903, 0.002084627145546128, 0.002069081496261788, 0.0020468276833233664, 0.0020358311024909915, 0.0020170094910865, 0.002005629295940509, 0.0019986327626532567, 0.001987249082722963, 0.001976017972770145, 0.0019721818402367265, 0.0019713217817935056, 0.0019618248162472916, 0.0019597732687828924, 0.0019446921859329603, 0.0019386975184837911, 0.0019299354133908442, 0.0019196010228725883, 0.0019166160415106828] \n",
      "\n",
      "learning rate: 0.0003864055330490959 \n",
      "test_rmse_score: 0.03887775 \n",
      "trainingMSE: [0.007437386352875861, 0.0028732630406353983, 0.00257424811139095, 0.002444431499299727, 0.0023647414277624106, 0.0023111510976838285, 0.0022725503765343197, 0.002219867684468904, 0.0021979780718296513, 0.0021641857882315303, 0.0021407196434177203, 0.0021154328195732985, 0.0021032884218509227, 0.0020877799651866603, 0.0020707372843114416, 0.002056519863712387, 0.0020339228775285434, 0.002026253298027827, 0.0020191601870611295, 0.002014945618316453, 0.0019966937586629874, 0.0019908321201575975, 0.0019766085298010393, 0.0019671241250641433, 0.0019561958512375023, 0.0019607336119125884, 0.0019417040799013553, 0.00192284210296532, 0.001932060238409844, 0.0019140120521940617] \n",
      "\n",
      "learning rate: 0.0021440241366783384 \n",
      "test_rmse_score: 0.04560053 \n",
      "trainingMSE: [0.004098301321559888, 0.002882784965069723, 0.002697731930673042, 0.0025518794580644956, 0.0024565931714759003, 0.00240078944750835, 0.0023621325357435774, 0.0023228748589388315, 0.0022884934355568514, 0.0022714009601765297, 0.002268446262881505, 0.00225261656126109, 0.0022470959706300787, 0.002254886019383172, 0.0022365853525325935, 0.0022330067033764197, 0.0022078607497056954, 0.002222851325945355, 0.0022145148263066823, 0.0021853616274652202, 0.00219323699330231, 0.0021956259813387317, 0.002200832440622915, 0.0021939240219240193, 0.002186605418475645, 0.0022070834461221964, 0.002217281471024069, 0.0021880980807750445, 0.0021788278804201807, 0.002199780065861062] \n",
      "\n",
      "learning rate: 0.0010590969847396408 \n",
      "test_rmse_score: 0.040224455 \n",
      "trainingMSE: [0.004490229336999178, 0.002647100805012707, 0.002465973693947956, 0.0023731250919036785, 0.0023123401157332476, 0.0022725014373978854, 0.00222833032063452, 0.002210737641430413, 0.0021778931436247494, 0.002161137228641162, 0.002144942321279063, 0.0021285072441022193, 0.0021155768922573475, 0.0020996874934182713, 0.002092589424605187, 0.002089994978860555, 0.002073083269422798, 0.002057596894474336, 0.0020622274669099007, 0.002045572915175288, 0.002051723655405852, 0.0020444410122902896, 0.0020263339516521884, 0.0020205785014022135, 0.00202084787508304, 0.00200992220458218, 0.0020065548810477775, 0.0020028762868991527, 0.0020025139121526035, 0.001988326155636286] \n",
      "\n",
      "learning rate: 0.00018325738942008386 \n",
      "test_rmse_score: 0.040142275 \n",
      "trainingMSE: [0.009929243234105876, 0.0031655875242059474, 0.0027422222802808787, 0.0025724152248195477, 0.002484630669674715, 0.0024072943566561963, 0.00235627469894819, 0.002311227419038201, 0.002285621327128695, 0.0022476822438117798, 0.0022270233924817353, 0.0022074320948367128, 0.002182793157976387, 0.002162475827232537, 0.002141438608368473, 0.00213411411709276, 0.0021240230708702208, 0.0021064148083865166, 0.0020927562288899767, 0.0020809716805115256, 0.00207043652167359, 0.0020579406515892676, 0.0020492143885683786, 0.0020408792503209387, 0.002030603398112792, 0.002026169255675596, 0.002009853742361625, 0.0020047535886735424, 0.0019926336373709426, 0.0019910411854215954] \n",
      "\n",
      "learning rate: 0.0006757376627292203 \n",
      "test_rmse_score: 0.03959008 \n",
      "trainingMSE: [0.004599632664371713, 0.0026185126360835495, 0.0024289284723383446, 0.0023311200637369557, 0.002256080865797388, 0.002216915093607544, 0.0021851357809509826, 0.0021554888766758882, 0.00212700292484821, 0.0021092114650575213, 0.0020883192607302915, 0.0020811912592555997, 0.002069703951237426, 0.002056820995212059, 0.002043280433619469, 0.002031024185836171, 0.002020395339022529, 0.002000385090204002, 0.00200548671011258, 0.0019966580648350463, 0.001986225882717348, 0.001981531745297434, 0.0019582154640975877, 0.0019624719810253906, 0.0019484601500503133, 0.0019515546520429325, 0.001940007174401366, 0.0019423351095965583, 0.0019303686570467957, 0.0019201320466373877] \n",
      "\n",
      "learning rate: 0.0009506006748680364 \n",
      "test_rmse_score: 0.03938766 \n",
      "trainingMSE: [0.004948034689431341, 0.0027201853005222793, 0.0025034950964483715, 0.0023851746949436242, 0.0023206480251019156, 0.002260600359070949, 0.0022329293473866865, 0.0021982878857864734, 0.002176386493408352, 0.002152143315719249, 0.002139990970852306, 0.0021195791456371524, 0.002110147978197812, 0.0020773568479805064, 0.002075802053103007, 0.002062231267477312, 0.0020563189616802377, 0.0020516119690890547, 0.0020386435423978113, 0.002028260589784664, 0.002005809968611146, 0.0020114052548910162, 0.0020033963092376344, 0.001991157959393333, 0.00198008238821452, 0.0019830331047569322, 0.0019764129964300018, 0.001968694688385462, 0.0019553029089509682, 0.0019546505025434075] \n",
      "\n",
      "learning rate: 0.0004651719417607577 \n",
      "test_rmse_score: 0.03931956 \n",
      "trainingMSE: [0.00795599090684594, 0.002967593136657221, 0.002619381897043297, 0.0024691996567110168, 0.002375697195137668, 0.002318282517984597, 0.0022687347306819994, 0.0022428435929253087, 0.002201599145676755, 0.002172463617433145, 0.002150334260352003, 0.0021359139435061627, 0.002124208007612553, 0.0020896840530226952, 0.0020936380910730992, 0.0020704044890797967, 0.0020568015927329487, 0.002044757872969606, 0.002039160524353016, 0.002025813818975505, 0.0020131415824066017, 0.002004837929455651, 0.0019916922884391994, 0.0019898285526698777, 0.0019841387146028204, 0.0019768987348978253, 0.0019682764552953163, 0.0019649604632907807, 0.0019547626583625954, 0.0019499226046465145] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.0004031371251971909 \n",
      "test_rmse_score: 0.039509486 \n",
      "trainingMSE: [0.006042782609405047, 0.0027212968533819304, 0.0024771636925630777, 0.0023555976964424533, 0.002295930397385803, 0.002236511985749564, 0.0021963394286855283, 0.0021727758965896338, 0.002146452911234741, 0.0021208922412897387, 0.0020941504246212625, 0.0020784725413669886, 0.0020629577659700368, 0.002038430783150679, 0.0020269683616844177, 0.0020150679528580903, 0.002002426071923934, 0.001988743380123035, 0.001986618613385912, 0.0019681004775051387, 0.0019603080476301112, 0.001943016224403021, 0.001938645602537483, 0.0019236936526468903, 0.0019146788519561365, 0.001910346001645408, 0.001907588914203628, 0.0019023570296363597, 0.0018894270876994794, 0.0018833415936973389] \n",
      "\n",
      "learning rate: 0.0007233150504950154 \n",
      "test_rmse_score: 0.039816983 \n",
      "trainingMSE: [0.006886238434719716, 0.0028781805688670504, 0.002583531465364596, 0.0024428193725336126, 0.0023591689601767662, 0.0022949131329522768, 0.0022477994975837485, 0.002217942212241171, 0.0021870511343225407, 0.002163624363424511, 0.0021343774611728887, 0.002126212951861737, 0.002104384841963647, 0.002088033960205047, 0.002069397953043619, 0.002062834314211094, 0.0020491162741506906, 0.0020373903767289133, 0.0020256699813559357, 0.0020109813874967554, 0.0020073813299786446, 0.0019966523388695104, 0.001976334482514721, 0.0019785328562710804, 0.001978690536773985, 0.0019651822144426353, 0.001963555848998309, 0.001942842783826669, 0.0019356806784080417, 0.0019332209876734207] \n",
      "\n",
      "learning rate: 0.0011170839581399515 \n",
      "test_rmse_score: 0.040024195 \n",
      "trainingMSE: [0.004999661019393635, 0.002797578017159481, 0.002570387142824219, 0.002449316342548117, 0.002361095252659423, 0.0023012915445297846, 0.00225934325699025, 0.0022357857418060017, 0.002198969041917714, 0.0021753824641181454, 0.0021527001947564657, 0.0021343459338367546, 0.0021133138361638325, 0.002102753520910571, 0.002090258442781786, 0.002076944490991246, 0.0020701371334844545, 0.002051622215289696, 0.0020500239554410594, 0.002043309987551009, 0.002029489238225217, 0.0020189852666148158, 0.002015342904465225, 0.002011576269512747, 0.002013990366756954, 0.001994366433113158, 0.001984022378017504, 0.0019784873202911882, 0.001972297684285838, 0.001974572709135824] \n",
      "\n",
      "learning rate: 0.00135497477886335 \n",
      "test_rmse_score: 0.040352196 \n",
      "trainingMSE: [0.004115803792551259, 0.0026578760508726967, 0.0024746525489006323, 0.0023713172365952833, 0.0023281940567845137, 0.0022761092177938703, 0.002246794812575129, 0.0022230280787387067, 0.0022024251459657794, 0.00218004502621658, 0.002166981517132175, 0.0021592572128027337, 0.002149423861292835, 0.002132375498142301, 0.0021193613083067744, 0.00210672966541005, 0.002101934361361457, 0.002098358254579682, 0.002084476311441752, 0.0020843510571204146, 0.0020834986164537427, 0.002069479173134784, 0.0020621946072777956, 0.0020555630298537543, 0.002058565355125748, 0.002041506170361522, 0.002044316564149427, 0.0020403965311423847, 0.0020393647933563785, 0.0020309774179408727] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while count < 15:\n",
    "    actv = 'sigmoid'\n",
    "    rande = -1.5 * np.random.rand() - 2.5  # range from -2.5 to -4. To shrink down the range: -0.5 * np.random.rand() - 3\n",
    "    alpha = 10**rande  # range from 0.0001 to 0.00316\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, 50, name = 'building_id_emb')(input_building_id)\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(20, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "#    building_id_emb = layers.Dropout(0.1)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, 8, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "#    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(4, activation=actv)(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "#    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation=actv)(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation=actv)(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, 8, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation=actv)(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(50, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(20, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha,beta_1=0.9,beta_2=0.999, epsilon=1e-08)\n",
    "                  , loss='mse'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    history = model.fit(X_srch, y_srch, epochs=30\n",
    "              , batch_size=64\n",
    "              , verbose=0\n",
    "             )\n",
    "    \n",
    "    test_pred = model.predict(X_test_srch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_srch, test_pred))\n",
    "    print('learning rate:',alpha,'\\ntest_rmse_score:',\n",
    "          test_rmse,'\\ntrainingMSE:',history.history.get('loss'),'\\n') \n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick lr = 0.0003864 with smallest test rmse score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bulidingid_neurons_1: 80 \n",
      "bulidingid_neurons_2: 25 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 47 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04095823\n",
      "\n",
      "bulidingid_neurons_1: 90 \n",
      "bulidingid_neurons_2: 15 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 70 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.041184414\n",
      "\n",
      "bulidingid_neurons_1: 100 \n",
      "bulidingid_neurons_2: 38 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 53 \n",
      "main_neurons_2: 58 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 20 \n",
      "test_rmse_score: 0.04044641\n",
      "\n",
      "bulidingid_neurons_1: 66 \n",
      "bulidingid_neurons_2: 38 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 47 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04126471\n",
      "\n",
      "bulidingid_neurons_1: 91 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 59 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 31 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.040420044\n",
      "\n",
      "bulidingid_neurons_1: 96 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 64 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.04052012\n",
      "\n",
      "bulidingid_neurons_1: 40 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 67 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 23 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.041208792\n",
      "\n",
      "bulidingid_neurons_1: 55 \n",
      "bulidingid_neurons_2: 37 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 68 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 32 \n",
      "main_neurons_5: 20 \n",
      "test_rmse_score: 0.04071716\n",
      "\n",
      "bulidingid_neurons_1: 71 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 57 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.041029595\n",
      "\n",
      "bulidingid_neurons_1: 66 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 70 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.0406655\n",
      "\n",
      "bulidingid_neurons_1: 73 \n",
      "bulidingid_neurons_2: 38 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 79 \n",
      "main_neurons_3: 50 \n",
      "main_neurons_4: 32 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.041138344\n",
      "\n",
      "bulidingid_neurons_1: 50 \n",
      "bulidingid_neurons_2: 27 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 59 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 32 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.043491997\n",
      "\n",
      "bulidingid_neurons_1: 55 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 65 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 23 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.04111157\n",
      "\n",
      "bulidingid_neurons_1: 100 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 69 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 25 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.04100413\n",
      "\n",
      "bulidingid_neurons_1: 99 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 57 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.041002043\n",
      "\n",
      "bulidingid_neurons_1: 100 \n",
      "bulidingid_neurons_2: 32 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 70 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04120729\n",
      "\n",
      "bulidingid_neurons_1: 45 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 74 \n",
      "main_neurons_3: 53 \n",
      "main_neurons_4: 25 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.04073983\n",
      "\n",
      "bulidingid_neurons_1: 86 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.04046607\n",
      "\n",
      "bulidingid_neurons_1: 87 \n",
      "bulidingid_neurons_2: 26 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 79 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 31 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.04172246\n",
      "\n",
      "bulidingid_neurons_1: 97 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 73 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.041651372\n",
      "\n",
      "bulidingid_neurons_1: 47 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.042136714\n",
      "\n",
      "bulidingid_neurons_1: 40 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 68 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.0409503\n",
      "\n",
      "bulidingid_neurons_1: 71 \n",
      "bulidingid_neurons_2: 20 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 27 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.04066207\n",
      "\n",
      "bulidingid_neurons_1: 53 \n",
      "bulidingid_neurons_2: 28 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 50 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 23 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.041715167\n",
      "\n",
      "bulidingid_neurons_1: 41 \n",
      "bulidingid_neurons_2: 16 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 50 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 21 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.040639058\n",
      "\n",
      "bulidingid_neurons_1: 98 \n",
      "bulidingid_neurons_2: 32 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 45 \n",
      "main_neurons_2: 60 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.041713826\n",
      "\n",
      "bulidingid_neurons_1: 76 \n",
      "bulidingid_neurons_2: 21 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 51 \n",
      "main_neurons_3: 48 \n",
      "main_neurons_4: 20 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.040196314\n",
      "\n",
      "bulidingid_neurons_1: 71 \n",
      "bulidingid_neurons_2: 40 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 65 \n",
      "main_neurons_3: 48 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.04064443\n",
      "\n",
      "bulidingid_neurons_1: 91 \n",
      "bulidingid_neurons_2: 39 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 75 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 33 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04087012\n",
      "\n",
      "bulidingid_neurons_1: 97 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 69 \n",
      "main_neurons_3: 50 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.040270504\n",
      "\n",
      "bulidingid_neurons_1: 45 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 45 \n",
      "main_neurons_2: 53 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.040861484\n",
      "\n",
      "bulidingid_neurons_1: 100 \n",
      "bulidingid_neurons_2: 37 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 79 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.0405428\n",
      "\n",
      "bulidingid_neurons_1: 92 \n",
      "bulidingid_neurons_2: 32 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 54 \n",
      "main_neurons_3: 47 \n",
      "main_neurons_4: 20 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04059543\n",
      "\n",
      "bulidingid_neurons_1: 51 \n",
      "bulidingid_neurons_2: 28 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 54 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 36 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.042396795\n",
      "\n",
      "bulidingid_neurons_1: 72 \n",
      "bulidingid_neurons_2: 37 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 54 \n",
      "main_neurons_3: 51 \n",
      "main_neurons_4: 21 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.04102196\n",
      "\n",
      "bulidingid_neurons_1: 53 \n",
      "bulidingid_neurons_2: 35 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 78 \n",
      "main_neurons_3: 47 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.041615356\n",
      "\n",
      "bulidingid_neurons_1: 44 \n",
      "bulidingid_neurons_2: 18 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 52 \n",
      "main_neurons_2: 68 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04112864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bulidingid_neurons_1: 75 \n",
      "bulidingid_neurons_2: 36 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 45 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.04082933\n",
      "\n",
      "bulidingid_neurons_1: 52 \n",
      "bulidingid_neurons_2: 15 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.04171475\n",
      "\n",
      "bulidingid_neurons_1: 88 \n",
      "bulidingid_neurons_2: 33 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 50 \n",
      "main_neurons_4: 26 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.040410202\n",
      "\n",
      "bulidingid_neurons_1: 92 \n",
      "bulidingid_neurons_2: 39 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 76 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.041413\n",
      "\n",
      "bulidingid_neurons_1: 90 \n",
      "bulidingid_neurons_2: 25 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 78 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 27 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.041391604\n",
      "\n",
      "bulidingid_neurons_1: 52 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 56 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 23 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.041058317\n",
      "\n",
      "bulidingid_neurons_1: 49 \n",
      "bulidingid_neurons_2: 20 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 45 \n",
      "main_neurons_2: 50 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.04239773\n",
      "\n",
      "bulidingid_neurons_1: 71 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 70 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 32 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.0411612\n",
      "\n",
      "bulidingid_neurons_1: 57 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 65 \n",
      "main_neurons_3: 50 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04172738\n",
      "\n",
      "bulidingid_neurons_1: 98 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 21 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04105685\n",
      "\n",
      "bulidingid_neurons_1: 90 \n",
      "bulidingid_neurons_2: 32 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 49 \n",
      "main_neurons_2: 56 \n",
      "main_neurons_3: 53 \n",
      "main_neurons_4: 20 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.04020674\n",
      "\n",
      "bulidingid_neurons_1: 75 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04052066\n",
      "\n",
      "bulidingid_neurons_1: 68 \n",
      "bulidingid_neurons_2: 38 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 73 \n",
      "main_neurons_3: 51 \n",
      "main_neurons_4: 38 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04102163\n",
      "\n",
      "bulidingid_neurons_1: 83 \n",
      "bulidingid_neurons_2: 21 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 54 \n",
      "main_neurons_2: 76 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.04042431\n",
      "\n",
      "bulidingid_neurons_1: 78 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 75 \n",
      "main_neurons_3: 43 \n",
      "main_neurons_4: 37 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.04090286\n",
      "\n",
      "bulidingid_neurons_1: 49 \n",
      "bulidingid_neurons_2: 24 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 46 \n",
      "main_neurons_2: 68 \n",
      "main_neurons_3: 47 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.041216485\n",
      "\n",
      "bulidingid_neurons_1: 84 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 67 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 40 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.04085835\n",
      "\n",
      "bulidingid_neurons_1: 95 \n",
      "bulidingid_neurons_2: 26 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 68 \n",
      "main_neurons_3: 48 \n",
      "main_neurons_4: 37 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.0407753\n",
      "\n",
      "bulidingid_neurons_1: 79 \n",
      "bulidingid_neurons_2: 35 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.041641403\n",
      "\n",
      "bulidingid_neurons_1: 43 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 36 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.04115618\n",
      "\n",
      "bulidingid_neurons_1: 47 \n",
      "bulidingid_neurons_2: 34 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 65 \n",
      "main_neurons_3: 43 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.041068282\n",
      "\n",
      "bulidingid_neurons_1: 88 \n",
      "bulidingid_neurons_2: 19 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 69 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 31 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.04085449\n",
      "\n",
      "bulidingid_neurons_1: 41 \n",
      "bulidingid_neurons_2: 16 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 70 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 27 \n",
      "main_neurons_5: 18 \n",
      "test_rmse_score: 0.041116074\n",
      "\n",
      "bulidingid_neurons_1: 51 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 64 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.040564973\n",
      "\n",
      "bulidingid_neurons_1: 42 \n",
      "bulidingid_neurons_2: 38 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 48 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.04088075\n",
      "\n",
      "bulidingid_neurons_1: 73 \n",
      "bulidingid_neurons_2: 39 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 77 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 33 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.04054805\n",
      "\n",
      "bulidingid_neurons_1: 50 \n",
      "bulidingid_neurons_2: 16 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 49 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 53 \n",
      "main_neurons_4: 25 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.041462466\n",
      "\n",
      "bulidingid_neurons_1: 47 \n",
      "bulidingid_neurons_2: 23 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 75 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 23 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.040512104\n",
      "\n",
      "bulidingid_neurons_1: 76 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 54 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.041293103\n",
      "\n",
      "bulidingid_neurons_1: 48 \n",
      "bulidingid_neurons_2: 19 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 33 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.041043088\n",
      "\n",
      "bulidingid_neurons_1: 87 \n",
      "bulidingid_neurons_2: 25 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 43 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 43 \n",
      "main_neurons_4: 37 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.040675536\n",
      "\n",
      "bulidingid_neurons_1: 56 \n",
      "bulidingid_neurons_2: 23 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 52 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 52 \n",
      "main_neurons_4: 27 \n",
      "main_neurons_5: 20 \n",
      "test_rmse_score: 0.040770605\n",
      "\n",
      "bulidingid_neurons_1: 77 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 51 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.040495273\n",
      "\n",
      "bulidingid_neurons_1: 78 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 56 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 24 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04084748\n",
      "\n",
      "bulidingid_neurons_1: 43 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 60 \n",
      "main_neurons_3: 48 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.04139046\n",
      "\n",
      "bulidingid_neurons_1: 59 \n",
      "bulidingid_neurons_2: 26 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 76 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 34 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.04087992\n",
      "\n",
      "bulidingid_neurons_1: 68 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 61 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 29 \n",
      "main_neurons_5: 12 \n",
      "test_rmse_score: 0.041594964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bulidingid_neurons_1: 62 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 53 \n",
      "main_neurons_2: 76 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 34 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.040334623\n",
      "\n",
      "bulidingid_neurons_1: 56 \n",
      "bulidingid_neurons_2: 24 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 66 \n",
      "main_neurons_3: 49 \n",
      "main_neurons_4: 40 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.041510653\n",
      "\n",
      "bulidingid_neurons_1: 94 \n",
      "bulidingid_neurons_2: 26 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 76 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 40 \n",
      "main_neurons_5: 15 \n",
      "test_rmse_score: 0.040615387\n",
      "\n",
      "bulidingid_neurons_1: 72 \n",
      "bulidingid_neurons_2: 26 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 50 \n",
      "main_neurons_2: 57 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 38 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.041500725\n",
      "\n",
      "bulidingid_neurons_1: 68 \n",
      "bulidingid_neurons_2: 16 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 47 \n",
      "main_neurons_2: 72 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 40 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.04096837\n",
      "\n",
      "bulidingid_neurons_1: 71 \n",
      "bulidingid_neurons_2: 32 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 55 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 51 \n",
      "main_neurons_4: 27 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.04078822\n",
      "\n",
      "bulidingid_neurons_1: 92 \n",
      "bulidingid_neurons_2: 36 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 52 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.04113596\n",
      "\n",
      "bulidingid_neurons_1: 52 \n",
      "bulidingid_neurons_2: 21 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 51 \n",
      "main_neurons_3: 40 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.04141906\n",
      "\n",
      "bulidingid_neurons_1: 89 \n",
      "bulidingid_neurons_2: 36 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 72 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.040619664\n",
      "\n",
      "bulidingid_neurons_1: 91 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 45 \n",
      "main_neurons_2: 59 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.04091949\n",
      "\n",
      "bulidingid_neurons_1: 56 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 13 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 37 \n",
      "main_neurons_5: 13 \n",
      "test_rmse_score: 0.041384805\n",
      "\n",
      "bulidingid_neurons_1: 90 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 48 \n",
      "main_neurons_2: 78 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.040390607\n",
      "\n",
      "bulidingid_neurons_1: 63 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 10 \n",
      "main_neurons_1: 41 \n",
      "main_neurons_2: 53 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 31 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.040700626\n",
      "\n",
      "bulidingid_neurons_1: 72 \n",
      "bulidingid_neurons_2: 31 \n",
      "primaryuse_neurons: 11 \n",
      "hour_neurons: 6 \n",
      "main_neurons_1: 53 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 41 \n",
      "main_neurons_4: 39 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.041196186\n",
      "\n",
      "bulidingid_neurons_1: 63 \n",
      "bulidingid_neurons_2: 39 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 46 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 32 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.040688965\n",
      "\n",
      "bulidingid_neurons_1: 59 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 49 \n",
      "main_neurons_2: 79 \n",
      "main_neurons_3: 55 \n",
      "main_neurons_4: 20 \n",
      "main_neurons_5: 19 \n",
      "test_rmse_score: 0.040478237\n",
      "\n",
      "bulidingid_neurons_1: 64 \n",
      "bulidingid_neurons_2: 17 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 51 \n",
      "main_neurons_2: 57 \n",
      "main_neurons_3: 50 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.040902432\n",
      "\n",
      "bulidingid_neurons_1: 84 \n",
      "bulidingid_neurons_2: 33 \n",
      "primaryuse_neurons: 6 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 54 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 26 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.040684074\n",
      "\n",
      "bulidingid_neurons_1: 83 \n",
      "bulidingid_neurons_2: 24 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 65 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 21 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.042433884\n",
      "\n",
      "bulidingid_neurons_1: 43 \n",
      "bulidingid_neurons_2: 22 \n",
      "primaryuse_neurons: 10 \n",
      "hour_neurons: 12 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 61 \n",
      "main_neurons_3: 43 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.040889204\n",
      "\n",
      "bulidingid_neurons_1: 59 \n",
      "bulidingid_neurons_2: 18 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 50 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 28 \n",
      "main_neurons_5: 14 \n",
      "test_rmse_score: 0.04080199\n",
      "\n",
      "bulidingid_neurons_1: 47 \n",
      "bulidingid_neurons_2: 29 \n",
      "primaryuse_neurons: 7 \n",
      "hour_neurons: 9 \n",
      "main_neurons_1: 40 \n",
      "main_neurons_2: 50 \n",
      "main_neurons_3: 45 \n",
      "main_neurons_4: 22 \n",
      "main_neurons_5: 16 \n",
      "test_rmse_score: 0.04103966\n",
      "\n",
      "bulidingid_neurons_1: 98 \n",
      "bulidingid_neurons_2: 33 \n",
      "primaryuse_neurons: 12 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 53 \n",
      "main_neurons_2: 52 \n",
      "main_neurons_3: 44 \n",
      "main_neurons_4: 30 \n",
      "main_neurons_5: 17 \n",
      "test_rmse_score: 0.040641245\n",
      "\n",
      "bulidingid_neurons_1: 94 \n",
      "bulidingid_neurons_2: 30 \n",
      "primaryuse_neurons: 8 \n",
      "hour_neurons: 7 \n",
      "main_neurons_1: 42 \n",
      "main_neurons_2: 62 \n",
      "main_neurons_3: 42 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 11 \n",
      "test_rmse_score: 0.040982913\n",
      "\n",
      "bulidingid_neurons_1: 59 \n",
      "bulidingid_neurons_2: 24 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 8 \n",
      "main_neurons_1: 52 \n",
      "main_neurons_2: 77 \n",
      "main_neurons_3: 46 \n",
      "main_neurons_4: 25 \n",
      "main_neurons_5: 20 \n",
      "test_rmse_score: 0.04038801\n",
      "\n",
      "bulidingid_neurons_1: 82 \n",
      "bulidingid_neurons_2: 21 \n",
      "primaryuse_neurons: 9 \n",
      "hour_neurons: 11 \n",
      "main_neurons_1: 44 \n",
      "main_neurons_2: 71 \n",
      "main_neurons_3: 54 \n",
      "main_neurons_4: 35 \n",
      "main_neurons_5: 10 \n",
      "test_rmse_score: 0.040599614\n",
      "Wall time: 1d 1h 51min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "while count < 100:\n",
    "    \n",
    "    # nesting loop for each random values are way better than random all of them in one loop\n",
    "    # but due to limitation of pc, I can't do it for this large data set\n",
    "    bulidingid_neurons_1 = rd.randint(40,100)\n",
    "    bulidingid_neurons_2 = rd.randint(15,40)\n",
    "    primaryuse_neurons = rd.randint(6,12)\n",
    "    hour_neurons = rd.randint(6,13)\n",
    "    main_neurons_1 = rd.randint(40,55)\n",
    "    main_neurons_2 = rd.randint(50,80)\n",
    "    main_neurons_3 = rd.randint(40,55)\n",
    "    main_neurons_4 = rd.randint(20,40)\n",
    "    main_neurons_5 = rd.randint(10,20)\n",
    "    \n",
    "    actv = 'sigmoid'\n",
    "    alpha = 0.0003864\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, bulidingid_neurons_1, name = 'building_id_emb')(input_building_id)\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(bulidingid_neurons_2, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "#    building_id_emb = layers.Dropout(0.1)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, primaryuse_neurons, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "#    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(4, activation=actv)(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "#    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation=actv)(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation=actv)(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, hour_neurons, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation=actv)(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    # input size = 32\n",
    "    main_Layers = layers.Dense(main_neurons_1, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_2, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_3, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_4, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha,beta_1=0.9,beta_2=0.999, epsilon=1e-08)\n",
    "                  , loss='mse'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    history = model.fit(X_srch, y_srch, epochs=12\n",
    "                        , batch_size=64\n",
    "                        , verbose=0\n",
    "                       )\n",
    "    \n",
    "    test_pred = model.predict(X_test_srch)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_srch, test_pred))\n",
    "    print('\\nbulidingid_neurons_1:',bulidingid_neurons_1,\n",
    "          '\\nbulidingid_neurons_2:',bulidingid_neurons_2,\n",
    "          '\\nprimaryuse_neurons:',primaryuse_neurons,\n",
    "          '\\nhour_neurons:',hour_neurons,\n",
    "          '\\nmain_neurons_1:',main_neurons_1,\n",
    "          '\\nmain_neurons_2:',main_neurons_2,\n",
    "          '\\nmain_neurons_3:',main_neurons_3,\n",
    "          '\\nmain_neurons_4:',main_neurons_4,\n",
    "          '\\nmain_neurons_5:',main_neurons_5,\n",
    "          '\\ntest_rmse_score:',test_rmse,\n",
    "#          '\\ntrainingMSE:',history.history.get('loss'),\n",
    "          ) \n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best test_rmse_score: 0.040196314\n",
    "1. bulidingid_neurons_1: 76 \n",
    "2. bulidingid_neurons_2: 21 \n",
    "3. primaryuse_neurons: 12 \n",
    "4. hour_neurons: 9 \n",
    "5. main_neurons_1: 54 \n",
    "6. main_neurons_2: 51 \n",
    "7. main_neurons_3: 48 \n",
    "8. main_neurons_4: 20 \n",
    "9. main_neurons_5: 11 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.1, random_state=99)\n",
    "for train_index, test_index in split.split(train_set0, train_set0.building_id):\n",
    "    strat_train_set0 = train_set0.iloc[train_index]\n",
    "    strat_test_set0 = train_set0.iloc[test_index]\n",
    "for train_index, test_index in split.split(train_set1, train_set1.building_id):\n",
    "    strat_train_set1 = train_set1.iloc[train_index]\n",
    "    strat_test_set1 = train_set1.iloc[test_index]\n",
    "for train_index, test_index in split.split(train_set2, train_set2.building_id):\n",
    "    strat_train_set2 = train_set2.iloc[train_index]\n",
    "    strat_test_set2 = train_set2.iloc[test_index]\n",
    "for train_index, test_index in split.split(train_set3, train_set3.building_id):\n",
    "    strat_train_set3 = train_set3.iloc[train_index]\n",
    "    strat_test_set3 = train_set3.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>sealev</th>\n",
       "      <th>dewtemp</th>\n",
       "      <th>windsp</th>\n",
       "      <th>North</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>nowind</th>\n",
       "      <th>dewair</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2109112</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>2016-10-21 14:00:00</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.630371</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.461440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125683</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149292</td>\n",
       "      <td>2016-05-23 13:00:00</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.561523</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.504062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5977866</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>2016-10-20 01:00:00</td>\n",
       "      <td>0.465088</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6091799</td>\n",
       "      <td>5</td>\n",
       "      <td>744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055298</td>\n",
       "      <td>2016-10-24 23:00:00</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.729492</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.240517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7026077</td>\n",
       "      <td>8</td>\n",
       "      <td>867</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075012</td>\n",
       "      <td>2016-04-28 18:00:00</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254639</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.431369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         site_id  building_id  primary_use  square_feet            timestamp  \\\n",
       "2109112        2          280            1     0.120300  2016-10-21 14:00:00   \n",
       "125683         0           23            0     0.149292  2016-05-23 13:00:00   \n",
       "5977866        5          731            0     0.032990  2016-10-20 01:00:00   \n",
       "6091799        5          744            1     0.055298  2016-10-24 23:00:00   \n",
       "7026077        8          867            9     0.075012  2016-04-28 18:00:00   \n",
       "\n",
       "          airtemp    sealev   dewtemp    windsp  North  West  South  nowind  \\\n",
       "2109112  0.676270  0.553223  0.630371  0.169434    1.0   0.0    0.0     0.0   \n",
       "125683   0.698242  0.561523  0.863770  0.107422    0.0   0.0    0.0     0.0   \n",
       "5977866  0.465088  0.554199  0.664551  0.061981    0.0   0.0    0.0     0.0   \n",
       "6091799  0.503906  0.554199  0.729492  0.210693    1.0   0.0    0.0     0.0   \n",
       "7026077  0.785156  0.576172  0.846191  0.061981    0.0   0.0    1.0     0.0   \n",
       "\n",
       "           dewair  month  weekday  hour  meter_reading  \n",
       "2109112  0.339111   10.0      4.0  14.0       0.461440  \n",
       "125683   0.120483    5.0      0.0  13.0       0.504062  \n",
       "5977866  0.022369   10.0      3.0   1.0       0.165838  \n",
       "6091799  0.005165   10.0      0.0  23.0       0.240517  \n",
       "7026077  0.254639    4.0      3.0  18.0       0.431369  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852404"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set0\n",
    "del train_set1\n",
    "del train_set2\n",
    "del train_set3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>sealev</th>\n",
       "      <th>dewtemp</th>\n",
       "      <th>windsp</th>\n",
       "      <th>North</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>nowind</th>\n",
       "      <th>dewair</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2109112</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>2016-10-21 14:00:00</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.630371</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.461440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125683</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149292</td>\n",
       "      <td>2016-05-23 13:00:00</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.561523</td>\n",
       "      <td>0.863770</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.504062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5977866</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>2016-10-20 01:00:00</td>\n",
       "      <td>0.465088</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6091799</td>\n",
       "      <td>5</td>\n",
       "      <td>744</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055298</td>\n",
       "      <td>2016-10-24 23:00:00</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.729492</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.240517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7026077</td>\n",
       "      <td>8</td>\n",
       "      <td>867</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075012</td>\n",
       "      <td>2016-04-28 18:00:00</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254639</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.431369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7736322</td>\n",
       "      <td>9</td>\n",
       "      <td>951</td>\n",
       "      <td>6</td>\n",
       "      <td>0.118469</td>\n",
       "      <td>2016-01-16 07:00:00</td>\n",
       "      <td>0.481934</td>\n",
       "      <td>0.495605</td>\n",
       "      <td>0.603027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.417256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8982323</td>\n",
       "      <td>13</td>\n",
       "      <td>1100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>2016-05-31 02:00:00</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>0.747070</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.498278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11294159</td>\n",
       "      <td>15</td>\n",
       "      <td>1393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173340</td>\n",
       "      <td>2016-05-06 16:00:00</td>\n",
       "      <td>0.561035</td>\n",
       "      <td>0.499268</td>\n",
       "      <td>0.638672</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.309043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2826109</td>\n",
       "      <td>3</td>\n",
       "      <td>362</td>\n",
       "      <td>9</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>2016-12-20 06:00:00</td>\n",
       "      <td>0.360107</td>\n",
       "      <td>0.858398</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.218744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3435001</td>\n",
       "      <td>3</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>2016-04-20 10:00:00</td>\n",
       "      <td>0.518066</td>\n",
       "      <td>0.688477</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.061981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.127777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10508636 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          site_id  building_id  primary_use  square_feet            timestamp  \\\n",
       "2109112         2          280            1     0.120300  2016-10-21 14:00:00   \n",
       "125683          0           23            0     0.149292  2016-05-23 13:00:00   \n",
       "5977866         5          731            0     0.032990  2016-10-20 01:00:00   \n",
       "6091799         5          744            1     0.055298  2016-10-24 23:00:00   \n",
       "7026077         8          867            9     0.075012  2016-04-28 18:00:00   \n",
       "...           ...          ...          ...          ...                  ...   \n",
       "7736322         9          951            6     0.118469  2016-01-16 07:00:00   \n",
       "8982323        13         1100            4     0.199707  2016-05-31 02:00:00   \n",
       "11294159       15         1393            1     0.173340  2016-05-06 16:00:00   \n",
       "2826109         3          362            9     0.024109  2016-12-20 06:00:00   \n",
       "3435001         3          434            0     0.044830  2016-04-20 10:00:00   \n",
       "\n",
       "           airtemp    sealev   dewtemp    windsp  North  West  South  nowind  \\\n",
       "2109112   0.676270  0.553223  0.630371  0.169434    1.0   0.0    0.0     0.0   \n",
       "125683    0.698242  0.561523  0.863770  0.107422    0.0   0.0    0.0     0.0   \n",
       "5977866   0.465088  0.554199  0.664551  0.061981    0.0   0.0    0.0     0.0   \n",
       "6091799   0.503906  0.554199  0.729492  0.210693    1.0   0.0    0.0     0.0   \n",
       "7026077   0.785156  0.576172  0.846191  0.061981    0.0   0.0    1.0     0.0   \n",
       "...            ...       ...       ...       ...    ...   ...    ...     ...   \n",
       "7736322   0.481934  0.495605  0.603027  0.000000    0.0   0.0    0.0     1.0   \n",
       "8982323   0.698242  0.528809  0.747070  0.235596    1.0   0.0    0.0     0.0   \n",
       "11294159  0.561035  0.499268  0.638672  0.235596    0.0   0.0    0.0     0.0   \n",
       "2826109   0.360107  0.858398  0.432617  0.148804    0.0   0.0    0.0     0.0   \n",
       "3435001   0.518066  0.688477  0.513672  0.061981    0.0   0.0    0.0     0.0   \n",
       "\n",
       "            dewair  month  weekday  hour  meter_reading  \n",
       "2109112   0.339111   10.0      4.0  14.0       0.461440  \n",
       "125683    0.120483    5.0      0.0  13.0       0.504062  \n",
       "5977866   0.022369   10.0      3.0   1.0       0.165838  \n",
       "6091799   0.005165   10.0      0.0  23.0       0.240517  \n",
       "7026077   0.254639    4.0      3.0  18.0       0.431369  \n",
       "...            ...    ...      ...   ...            ...  \n",
       "7736322   0.110168    1.0      5.0   7.0       0.417256  \n",
       "8982323   0.244385    5.0      1.0   2.0       0.498278  \n",
       "11294159  0.177246    5.0      4.0  16.0       0.309043  \n",
       "2826109   0.129028    0.0      1.0   6.0       0.218744  \n",
       "3435001   0.252930    4.0      2.0  10.0       0.127777  \n",
       "\n",
       "[10508636 rows x 18 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = [strat_train_set0.building_id.values, strat_train_set0.primary_use.values, \n",
    "      strat_train_set0.month.values, strat_train_set0.weekday.values, strat_train_set0.hour.values, \n",
    "      strat_train_set0.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y0 = strat_train_set0.meter_reading.values\n",
    "\n",
    "X1 = [strat_train_set1.building_id.values, strat_train_set1.primary_use.values, \n",
    "      strat_train_set1.month.values, strat_train_set1.weekday.values, strat_train_set1.hour.values, \n",
    "      strat_train_set1.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y1 = strat_train_set1.meter_reading.values\n",
    "\n",
    "X2 = [strat_train_set2.building_id.values, strat_train_set2.primary_use.values, \n",
    "      strat_train_set2.month.values, strat_train_set2.weekday.values, strat_train_set2.hour.values, \n",
    "      strat_train_set2.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y2 = strat_train_set2.meter_reading.values\n",
    "\n",
    "X3 = [strat_train_set3.building_id.values, strat_train_set3.primary_use.values, \n",
    "      strat_train_set3.month.values, strat_train_set3.weekday.values, strat_train_set3.hour.values, \n",
    "      strat_train_set3.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y3 = strat_train_set3.meter_reading.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_test = [strat_test_set0.building_id.values, strat_test_set0.primary_use.values, \n",
    "      strat_test_set0.month.values, strat_test_set0.weekday.values, strat_test_set0.hour.values, \n",
    "      strat_test_set0.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y0_test = strat_test_set0.meter_reading.values\n",
    "\n",
    "X1_test = [strat_test_set1.building_id.values, strat_test_set1.primary_use.values, \n",
    "      strat_test_set1.month.values, strat_test_set1.weekday.values, strat_test_set1.hour.values, \n",
    "      strat_test_set1.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y1_test = strat_test_set1.meter_reading.values\n",
    "\n",
    "X2_test = [strat_test_set2.building_id.values, strat_test_set2.primary_use.values, \n",
    "      strat_test_set2.month.values, strat_test_set2.weekday.values, strat_test_set2.hour.values, \n",
    "      strat_test_set2.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y2_test = strat_test_set2.meter_reading.values\n",
    "\n",
    "X3_test = [strat_test_set3.building_id.values, strat_test_set3.primary_use.values, \n",
    "      strat_test_set3.month.values, strat_test_set3.weekday.values, strat_test_set3.hour.values, \n",
    "      strat_test_set3.drop(['site_id','building_id','timestamp','meter_reading','dewair'], axis=1).values]\n",
    "y3_test = strat_test_set3.meter_reading.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the final neural network model\n",
    "with the structure and hyperpara I got from previous searches:\n",
    "6 main layers for this network; \n",
    "Sigmoid activation; \n",
    "lr = 0.0003864; \n",
    "bulidingid_neurons_1: 76; \n",
    "bulidingid_neurons_2: 21; \n",
    "primaryuse_neurons: 12; \n",
    "hour_neurons: 9; \n",
    "main_neurons_1: 54; \n",
    "main_neurons_2: 51; \n",
    "main_neurons_3: 48; \n",
    "main_neurons_4: 20; \n",
    "main_neurons_5: 11; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    bulidingid_neurons_1 = 76\n",
    "    bulidingid_neurons_2 = 21\n",
    "    primaryuse_neurons = 12\n",
    "    hour_neurons = 9\n",
    "    main_neurons_1 = 54\n",
    "    main_neurons_2 = 51\n",
    "    main_neurons_3 = 48\n",
    "    main_neurons_4 = 20\n",
    "    main_neurons_5 = 11\n",
    "    \n",
    "    actv = 'sigmoid'\n",
    "    alpha = 0.0003864\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, bulidingid_neurons_1, name = 'building_id_emb')(input_building_id)\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(bulidingid_neurons_2, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "#    building_id_emb = layers.Dropout(0.1)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation=actv)(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, primaryuse_neurons, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "#    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(4, activation=actv)(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "#    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation=actv)(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation=actv)(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, hour_neurons, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation=actv)(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    # input size = 32\n",
    "    main_Layers = layers.Dense(main_neurons_1, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_2, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_3, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_4, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dense(main_neurons_5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation=actv)(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "#    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha,beta_1=0.9,beta_2=0.999, epsilon=1e-08)\n",
    "                  , loss='mse'\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_building):\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    input_building_id = layers.Input(shape=(1,), name='input_building_id')\n",
    "    building_id_emb = layers.Embedding(1449, 20, name = 'building_id_emb')(input_building_id) # 1449\n",
    "    building_id_emb = layers.Flatten()(building_id_emb)\n",
    "    building_id_emb = layers.Dropout(0.2)(building_id_emb)\n",
    "    building_id_emb = layers.Dense(10, activation='relu')(building_id_emb)\n",
    "    building_id_emb = layers.BatchNormalization()(building_id_emb)\n",
    "   \n",
    "    embeddings.append(building_id_emb)\n",
    "    \n",
    "    input_primary_use = layers.Input(shape=(1,), name='input_primary_use')\n",
    "    primary_use_emb = layers.Embedding(16, 5, name = 'primary_use_emb')(input_primary_use)\n",
    "    primary_use_emb = layers.Flatten()(primary_use_emb)\n",
    "    primary_use_emb = layers.Dropout(0.1)(primary_use_emb)\n",
    "    primary_use_emb = layers.Dense(2, activation='relu')(primary_use_emb)\n",
    "    primary_use_emb = layers.BatchNormalization()(primary_use_emb)\n",
    "\n",
    "    embeddings.append(primary_use_emb)\n",
    "    \n",
    "    input_month = layers.Input(shape=(1,), name='input_month')\n",
    "    month_emb = layers.Embedding(12, 4, name = 'month_emb')(input_month)\n",
    "    month_emb = layers.Flatten()(month_emb)\n",
    "    month_emb = layers.Dropout(0.1)(month_emb)\n",
    "    month_emb = layers.Dense(2, activation='relu')(month_emb)\n",
    "    month_emb = layers.BatchNormalization()(month_emb)\n",
    "\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_weekday = layers.Input(shape=(1,), name='input_weekday')\n",
    "    weekday_emb = layers.Embedding(7, 3, name = 'month_emb')(input_weekday)\n",
    "    weekday_emb = layers.Flatten()(weekday_emb)\n",
    "    weekday_emb = layers.Dense(2, activation='relu')(weekday_emb)\n",
    "    weekday_emb = layers.BatchNormalization()(weekday_emb)\n",
    "\n",
    "    embeddings.append(month_emb)\n",
    "    \n",
    "    input_hour = layers.Input(shape=(1,), name='input_hour')\n",
    "    hour_emb = layers.Embedding(24, 6, name = 'hour_emb')(input_hour)\n",
    "    hour_emb = layers.Flatten()(hour_emb)\n",
    "    hour_emb = layers.Dense(3, activation='relu')(hour_emb)\n",
    "    hour_emb = layers.BatchNormalization()(hour_emb)\n",
    "\n",
    "    embeddings.append(hour_emb)\n",
    "\n",
    "    \n",
    "    input_numeric = layers.Input(shape=(13,), name = 'input_numeric')\n",
    "#    embedding_num = layers.Dense(35)(input_numeric)\n",
    "    \n",
    "    embeddings.append(input_numeric)\n",
    "    \n",
    "    main_Layers = layers.Concatenate()(embeddings)\n",
    "    \n",
    "    # input size = 32\n",
    "    main_Layers = layers.Dense(50, activation='relu')(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(20, activation='relu')(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    main_Layers = layers.Dense(5, activation='relu')(main_Layers)\n",
    "    main_Layers = layers.BatchNormalization()(main_Layers)\n",
    "    main_Layers = layers.Dropout(0.05)(main_Layers)\n",
    "    output = layers.Dense(1)(main_Layers)\n",
    "\n",
    "    model = tf.keras.Model([input_building_id, input_primary_use, input_month,\n",
    "                            input_weekday, input_hour, input_numeric], output)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001,beta_1=0.9,beta_2=0.999, epsilon=1e-08), \n",
    "                  loss='mse' # tf.keras.losses.mean_squared_error\n",
    "                  , metrics=['mae']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meter0 = build_model()\n",
    "model_meter1 = build_model()\n",
    "model_meter2 = build_model()\n",
    "model_meter3 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_145\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_building_id (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "building_id_emb (Embedding)     (None, 1, 76)        110124      input_building_id[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_730 (Flatten)           (None, 76)           0           building_id_emb[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 76)           0           flatten_730[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_primary_use (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_month (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_hour (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1866 (Dense)              (None, 21)           1617        dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "primary_use_emb (Embedding)     (None, 1, 12)        192         input_primary_use[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "month_emb (Embedding)           (None, 1, 4)         48          input_month[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hour_emb (Embedding)            (None, 1, 9)         216         input_hour[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1721 (Batch (None, 21)           84          dense_1866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_731 (Flatten)           (None, 12)           0           primary_use_emb[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_732 (Flatten)           (None, 4)            0           month_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_734 (Flatten)           (None, 9)            0           hour_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1867 (Dense)              (None, 10)           220         batch_normalization_1721[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1868 (Dense)              (None, 4)            52          flatten_731[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1869 (Dense)              (None, 2)            10          flatten_732[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1871 (Dense)              (None, 3)            30          flatten_734[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1722 (Batch (None, 10)           40          dense_1867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1723 (Batch (None, 4)            16          dense_1868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1724 (Batch (None, 2)            8           dense_1869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1726 (Batch (None, 3)            12          dense_1871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_numeric (InputLayer)      [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 34)           0           batch_normalization_1722[0][0]   \n",
      "                                                                 batch_normalization_1723[0][0]   \n",
      "                                                                 batch_normalization_1724[0][0]   \n",
      "                                                                 batch_normalization_1724[0][0]   \n",
      "                                                                 batch_normalization_1726[0][0]   \n",
      "                                                                 input_numeric[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1872 (Dense)              (None, 54)           1890        concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1727 (Batch (None, 54)           216         dense_1872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1873 (Dense)              (None, 51)           2805        batch_normalization_1727[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1728 (Batch (None, 51)           204         dense_1873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1874 (Dense)              (None, 48)           2496        batch_normalization_1728[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1729 (Batch (None, 48)           192         dense_1874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1875 (Dense)              (None, 20)           980         batch_normalization_1729[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1730 (Batch (None, 20)           80          dense_1875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1876 (Dense)              (None, 11)           231         batch_normalization_1730[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1731 (Batch (None, 11)           44          dense_1876[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1877 (Dense)              (None, 5)            60          batch_normalization_1731[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1732 (Batch (None, 5)            20          dense_1877[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_weekday (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1878 (Dense)              (None, 1)            6           batch_normalization_1732[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 121,893\n",
      "Trainable params: 121,435\n",
      "Non-trainable params: 458\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_meter0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: to loop early stopping to capture the model, next loop keep training to capture next model in early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10508636 samples\n",
      "Epoch 1/60\n",
      "10508636/10508636 [==============================] - 1874s 178us/sample - loss: 0.0027 - mae: 0.0304\n",
      "Epoch 2/60\n",
      "10508636/10508636 [==============================] - 1890s 180us/sample - loss: 0.0020 - mae: 0.0266\n",
      "Epoch 3/60\n",
      "10508636/10508636 [==============================] - 1903s 181us/sample - loss: 0.0019 - mae: 0.0260\n",
      "Epoch 4/60\n",
      "10508636/10508636 [==============================] - 1521s 145us/sample - loss: 0.0018 - mae: 0.0257\n",
      "Epoch 5/60\n",
      "10508636/10508636 [==============================] - 976s 93us/sample - loss: 0.0018 - mae: 0.0254\n",
      "Epoch 6/60\n",
      "10508636/10508636 [==============================] - 981s 93us/sample - loss: 0.0018 - mae: 0.0252\n",
      "Epoch 7/60\n",
      "10508636/10508636 [==============================] - 982s 93us/sample - loss: 0.0017 - mae: 0.0251\n",
      "Epoch 8/60\n",
      "10508636/10508636 [==============================] - 987s 94us/sample - loss: 0.0017 - mae: 0.0249\n",
      "Epoch 9/60\n",
      "10508636/10508636 [==============================] - 983s 94us/sample - loss: 0.0017 - mae: 0.0248\n",
      "Epoch 10/60\n",
      "10508636/10508636 [==============================] - 981s 93us/sample - loss: 0.0017 - mae: 0.0248\n",
      "Epoch 11/60\n",
      "10508636/10508636 [==============================] - 983s 94us/sample - loss: 0.0017 - mae: 0.0247\n",
      "Epoch 12/60\n",
      "10508636/10508636 [==============================] - 1006s 96us/sample - loss: 0.0017 - mae: 0.0246\n",
      "Epoch 13/60\n",
      "10508636/10508636 [==============================] - 978s 93us/sample - loss: 0.0017 - mae: 0.0246\n",
      "Epoch 14/60\n",
      "10508636/10508636 [==============================] - 979s 93us/sample - loss: 0.0017 - mae: 0.0246\n",
      "Epoch 15/60\n",
      "10508636/10508636 [==============================] - 984s 94us/sample - loss: 0.0017 - mae: 0.0246\n",
      "Epoch 16/60\n",
      "10508636/10508636 [==============================] - 981s 93us/sample - loss: 0.0017 - mae: 0.0245\n",
      "Epoch 17/60\n",
      "10508636/10508636 [==============================] - 982s 93us/sample - loss: 0.0017 - mae: 0.0245\n",
      "Epoch 18/60\n",
      "10508636/10508636 [==============================] - 983s 94us/sample - loss: 0.0017 - mae: 0.0244\n",
      "Epoch 19/60\n",
      "10508636/10508636 [==============================] - 989s 94us/sample - loss: 0.0017 - mae: 0.0245\n",
      "Epoch 20/60\n",
      "10508636/10508636 [==============================] - 993s 95us/sample - loss: 0.0017 - mae: 0.0244\n",
      "Epoch 21/60\n",
      "10508636/10508636 [==============================] - 1002s 95us/sample - loss: 0.0017 - mae: 0.0244\n",
      "Epoch 22/60\n",
      "10508636/10508636 [==============================] - 1048s 100us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 23/60\n",
      "10508636/10508636 [==============================] - 1050s 100us/sample - loss: 0.0016 - mae: 0.0244\n",
      "Epoch 24/60\n",
      "10508636/10508636 [==============================] - 1095s 104us/sample - loss: 0.0016 - mae: 0.0244\n",
      "Epoch 25/60\n",
      "10508636/10508636 [==============================] - 1091s 104us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 26/60\n",
      "10508636/10508636 [==============================] - 1053s 100us/sample - loss: 0.0016 - mae: 0.0244\n",
      "Epoch 27/60\n",
      "10508636/10508636 [==============================] - 1089s 104us/sample - loss: 0.0016 - mae: 0.0244\n",
      "Epoch 28/60\n",
      "10508636/10508636 [==============================] - 944s 90us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 29/60\n",
      "10508636/10508636 [==============================] - 1073s 102us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 30/60\n",
      "10508636/10508636 [==============================] - 1064s 101us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 31/60\n",
      "10508636/10508636 [==============================] - 1061s 101us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 32/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 33/60\n",
      "10508636/10508636 [==============================] - 931s 89us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 34/60\n",
      "10508636/10508636 [==============================] - 924s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 35/60\n",
      "10508636/10508636 [==============================] - 928s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 36/60\n",
      "10508636/10508636 [==============================] - 928s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 37/60\n",
      "10508636/10508636 [==============================] - 933s 89us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 38/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 39/60\n",
      "10508636/10508636 [==============================] - 928s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 40/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 41/60\n",
      "10508636/10508636 [==============================] - 933s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 42/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0243\n",
      "Epoch 43/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 44/60\n",
      "10508636/10508636 [==============================] - 930s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 45/60\n",
      "10508636/10508636 [==============================] - 933s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 46/60\n",
      "10508636/10508636 [==============================] - 928s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 47/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 48/60\n",
      "10508636/10508636 [==============================] - 931s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 49/60\n",
      "10508636/10508636 [==============================] - 930s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 50/60\n",
      "10508636/10508636 [==============================] - 930s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 51/60\n",
      "10508636/10508636 [==============================] - 928s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 52/60\n",
      "10508636/10508636 [==============================] - 934s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 53/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 54/60\n",
      "10508636/10508636 [==============================] - 931s 89us/sample - loss: 0.0016 - mae: 0.0241\n",
      "Epoch 55/60\n",
      "10508636/10508636 [==============================] - 929s 88us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 56/60\n",
      "10508636/10508636 [==============================] - 934s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 57/60\n",
      "10508636/10508636 [==============================] - 930s 89us/sample - loss: 0.0016 - mae: 0.0242\n",
      "Epoch 58/60\n",
      "10508636/10508636 [==============================] - 930s 89us/sample - loss: 0.0016 - mae: 0.0241\n",
      "Epoch 59/60\n",
      "10508636/10508636 [==============================] - 930s 89us/sample - loss: 0.0016 - mae: 0.0241\n",
      "Epoch 60/60\n",
      "10508636/10508636 [==============================] - 935s 89us/sample - loss: 0.0016 - mae: 0.0241\n"
     ]
    }
   ],
   "source": [
    "history = model_meter0.fit(X0, y0, epochs=60\n",
    "                           , batch_size=64\n",
    "#                          , verbose=0\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_meter0.predict(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034867074\n"
     ]
    }
   ],
   "source": [
    "test_rmse = np.sqrt(mean_squared_error(y0_test, test_pred))\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "model_meter0.save('model_meter0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3744081 samples\n",
      "Epoch 1/100\n",
      "3744081/3744081 [==============================] - 366s 98us/sample - loss: 0.0088 - mae: 0.0596\n",
      "Epoch 2/100\n",
      "3744081/3744081 [==============================] - 345s 92us/sample - loss: 0.0065 - mae: 0.0498\n",
      "Epoch 3/100\n",
      "3744081/3744081 [==============================] - 343s 91us/sample - loss: 0.0061 - mae: 0.0480\n",
      "Epoch 4/100\n",
      "3744081/3744081 [==============================] - 342s 91us/sample - loss: 0.0059 - mae: 0.0471\n",
      "Epoch 5/100\n",
      "3744081/3744081 [==============================] - 342s 91us/sample - loss: 0.0057 - mae: 0.0464\n",
      "Epoch 6/100\n",
      "3744081/3744081 [==============================] - 341s 91us/sample - loss: 0.0056 - mae: 0.0458\n",
      "Epoch 7/100\n",
      "3744081/3744081 [==============================] - 374s 100us/sample - loss: 0.0055 - mae: 0.0455\n",
      "Epoch 8/100\n",
      "3744081/3744081 [==============================] - 381s 102us/sample - loss: 0.0055 - mae: 0.0451\n",
      "Epoch 9/100\n",
      "3744081/3744081 [==============================] - 342s 91us/sample - loss: 0.0054 - mae: 0.0448\n",
      "Epoch 10/100\n",
      "3744081/3744081 [==============================] - 375s 100us/sample - loss: 0.0054 - mae: 0.0446\n",
      "Epoch 11/100\n",
      "3744081/3744081 [==============================] - 375s 100us/sample - loss: 0.0053 - mae: 0.0444\n",
      "Epoch 12/100\n",
      "3744081/3744081 [==============================] - 375s 100us/sample - loss: 0.0053 - mae: 0.0442\n",
      "Epoch 13/100\n",
      "3744081/3744081 [==============================] - 376s 101us/sample - loss: 0.0052 - mae: 0.0441\n",
      "Epoch 14/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0052 - mae: 0.0439\n",
      "Epoch 15/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0052 - mae: 0.0437\n",
      "Epoch 16/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0052 - mae: 0.0437\n",
      "Epoch 17/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0051 - mae: 0.0436\n",
      "Epoch 18/100\n",
      "3744081/3744081 [==============================] - 349s 93us/sample - loss: 0.0051 - mae: 0.0435\n",
      "Epoch 19/100\n",
      "3744081/3744081 [==============================] - 376s 100us/sample - loss: 0.0051 - mae: 0.0434\n",
      "Epoch 20/100\n",
      "3744081/3744081 [==============================] - 343s 92us/sample - loss: 0.0051 - mae: 0.0433\n",
      "Epoch 21/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0050 - mae: 0.0432\n",
      "Epoch 22/100\n",
      "3744081/3744081 [==============================] - 345s 92us/sample - loss: 0.0050 - mae: 0.0432\n",
      "Epoch 23/100\n",
      "3744081/3744081 [==============================] - 376s 100us/sample - loss: 0.0050 - mae: 0.0431\n",
      "Epoch 24/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0050 - mae: 0.0430\n",
      "Epoch 25/100\n",
      "3744081/3744081 [==============================] - 345s 92us/sample - loss: 0.0050 - mae: 0.0429\n",
      "Epoch 26/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0049 - mae: 0.0429\n",
      "Epoch 27/100\n",
      "3744081/3744081 [==============================] - 377s 101us/sample - loss: 0.0049 - mae: 0.0428\n",
      "Epoch 28/100\n",
      "3744081/3744081 [==============================] - 350s 93us/sample - loss: 0.0049 - mae: 0.0428\n",
      "Epoch 29/100\n",
      "3744081/3744081 [==============================] - 351s 94us/sample - loss: 0.0049 - mae: 0.0427\n",
      "Epoch 30/100\n",
      "3744081/3744081 [==============================] - 345s 92us/sample - loss: 0.0049 - mae: 0.0426\n",
      "Epoch 31/100\n",
      "3744081/3744081 [==============================] - 381s 102us/sample - loss: 0.0049 - mae: 0.0425\n",
      "Epoch 32/100\n",
      "3744081/3744081 [==============================] - 377s 101us/sample - loss: 0.0049 - mae: 0.0425\n",
      "Epoch 33/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0049 - mae: 0.0425\n",
      "Epoch 34/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0049 - mae: 0.0424\n",
      "Epoch 35/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0049 - mae: 0.0424\n",
      "Epoch 36/100\n",
      "3744081/3744081 [==============================] - 376s 101us/sample - loss: 0.0048 - mae: 0.0424\n",
      "Epoch 37/100\n",
      "3744081/3744081 [==============================] - 377s 101us/sample - loss: 0.0048 - mae: 0.0423\n",
      "Epoch 38/100\n",
      "3744081/3744081 [==============================] - 383s 102us/sample - loss: 0.0048 - mae: 0.0424\n",
      "Epoch 39/100\n",
      "3744081/3744081 [==============================] - 379s 101us/sample - loss: 0.0048 - mae: 0.0423\n",
      "Epoch 40/100\n",
      "3744081/3744081 [==============================] - 377s 101us/sample - loss: 0.0048 - mae: 0.0423\n",
      "Epoch 41/100\n",
      "3744081/3744081 [==============================] - 347s 93us/sample - loss: 0.0048 - mae: 0.0422\n",
      "Epoch 42/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0048 - mae: 0.0422\n",
      "Epoch 43/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0048 - mae: 0.0421\n",
      "Epoch 44/100\n",
      "3744081/3744081 [==============================] - 377s 101us/sample - loss: 0.0048 - mae: 0.0421\n",
      "Epoch 45/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0048 - mae: 0.0421\n",
      "Epoch 46/100\n",
      "3744081/3744081 [==============================] - 350s 93us/sample - loss: 0.0048 - mae: 0.0421\n",
      "Epoch 47/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0048 - mae: 0.0421\n",
      "Epoch 48/100\n",
      "3744081/3744081 [==============================] - 390s 104us/sample - loss: 0.0048 - mae: 0.0420\n",
      "Epoch 49/100\n",
      "3744081/3744081 [==============================] - 347s 93us/sample - loss: 0.0048 - mae: 0.0420\n",
      "Epoch 50/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0048 - mae: 0.0420\n",
      "Epoch 51/100\n",
      "3744081/3744081 [==============================] - 347s 93us/sample - loss: 0.0048 - mae: 0.0420\n",
      "Epoch 52/100\n",
      "3744081/3744081 [==============================] - 345s 92us/sample - loss: 0.0048 - mae: 0.0420\n",
      "Epoch 53/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0419\n",
      "Epoch 54/100\n",
      "3744081/3744081 [==============================] - 347s 93us/sample - loss: 0.0047 - mae: 0.0420\n",
      "Epoch 55/100\n",
      "3744081/3744081 [==============================] - 380s 101us/sample - loss: 0.0047 - mae: 0.0420\n",
      "Epoch 56/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0419\n",
      "Epoch 57/100\n",
      "3744081/3744081 [==============================] - 346s 93us/sample - loss: 0.0047 - mae: 0.0419\n",
      "Epoch 58/100\n",
      "3744081/3744081 [==============================] - 359s 96us/sample - loss: 0.0047 - mae: 0.0418\n",
      "Epoch 59/100\n",
      "3744081/3744081 [==============================] - 356s 95us/sample - loss: 0.0047 - mae: 0.0418\n",
      "Epoch 60/100\n",
      "3744081/3744081 [==============================] - 384s 102us/sample - loss: 0.0047 - mae: 0.0418\n",
      "Epoch 61/100\n",
      "3744081/3744081 [==============================] - 385s 103us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 62/100\n",
      "3744081/3744081 [==============================] - 380s 102us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 63/100\n",
      "3744081/3744081 [==============================] - 380s 101us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 64/100\n",
      "3744081/3744081 [==============================] - 380s 101us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 65/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 66/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 67/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 68/100\n",
      "3744081/3744081 [==============================] - 384s 103us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 69/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 70/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 71/100\n",
      "3744081/3744081 [==============================] - 379s 101us/sample - loss: 0.0047 - mae: 0.0417\n",
      "Epoch 72/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 73/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 74/100\n",
      "3744081/3744081 [==============================] - 346s 92us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3744081/3744081 [==============================] - 334s 89us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 76/100\n",
      "3744081/3744081 [==============================] - 333s 89us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 77/100\n",
      "3744081/3744081 [==============================] - 334s 89us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 78/100\n",
      "3744081/3744081 [==============================] - 340s 91us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 79/100\n",
      "3744081/3744081 [==============================] - 366s 98us/sample - loss: 0.0047 - mae: 0.0416\n",
      "Epoch 80/100\n",
      "3744081/3744081 [==============================] - 365s 98us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 81/100\n",
      "3744081/3744081 [==============================] - 367s 98us/sample - loss: 0.0046 - mae: 0.0415\n",
      "Epoch 82/100\n",
      "3744081/3744081 [==============================] - 335s 90us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 83/100\n",
      "3744081/3744081 [==============================] - 335s 89us/sample - loss: 0.0047 - mae: 0.0415\n",
      "Epoch 84/100\n",
      "3744081/3744081 [==============================] - 335s 89us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 85/100\n",
      "3744081/3744081 [==============================] - 368s 98us/sample - loss: 0.0046 - mae: 0.0415\n",
      "Epoch 86/100\n",
      "3744081/3744081 [==============================] - 366s 98us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 87/100\n",
      "3744081/3744081 [==============================] - 366s 98us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 88/100\n",
      "3744081/3744081 [==============================] - 340s 91us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 89/100\n",
      "3744081/3744081 [==============================] - 366s 98us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 90/100\n",
      "3744081/3744081 [==============================] - 344s 92us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 91/100\n",
      "3744081/3744081 [==============================] - 392s 105us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 92/100\n",
      "3744081/3744081 [==============================] - 379s 101us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 93/100\n",
      "3744081/3744081 [==============================] - 376s 100us/sample - loss: 0.0046 - mae: 0.0413\n",
      "Epoch 94/100\n",
      "3744081/3744081 [==============================] - 341s 91us/sample - loss: 0.0046 - mae: 0.0413\n",
      "Epoch 95/100\n",
      "3744081/3744081 [==============================] - 341s 91us/sample - loss: 0.0046 - mae: 0.0414\n",
      "Epoch 96/100\n",
      "3744081/3744081 [==============================] - 341s 91us/sample - loss: 0.0046 - mae: 0.0412\n",
      "Epoch 97/100\n",
      "3744081/3744081 [==============================] - 373s 100us/sample - loss: 0.0046 - mae: 0.0413\n",
      "Epoch 98/100\n",
      "3744081/3744081 [==============================] - 378s 101us/sample - loss: 0.0046 - mae: 0.0413\n",
      "Epoch 99/100\n",
      "3744081/3744081 [==============================] - 341s 91us/sample - loss: 0.0046 - mae: 0.0413\n",
      "Epoch 100/100\n",
      "3744081/3744081 [==============================] - 340s 91us/sample - loss: 0.0046 - mae: 0.0413\n"
     ]
    }
   ],
   "source": [
    "history = model_meter1.fit(X1, y1, epochs=100\n",
    "                           , batch_size=64\n",
    "#                          , verbose=0\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2418010 samples\n",
      "Epoch 1/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0079 - mae: 0.0565\n",
      "Epoch 2/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0052 - mae: 0.0457\n",
      "Epoch 3/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0050 - mae: 0.0440\n",
      "Epoch 4/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0048 - mae: 0.0430\n",
      "Epoch 5/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0047 - mae: 0.0425\n",
      "Epoch 6/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0046 - mae: 0.0420\n",
      "Epoch 7/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0046 - mae: 0.0417\n",
      "Epoch 8/150\n",
      "2418010/2418010 [==============================] - ETA: 0s - loss: 0.0045 - mae: 0.041 - 225s 93us/sample - loss: 0.0045 - mae: 0.0414\n",
      "Epoch 9/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0045 - mae: 0.0412\n",
      "Epoch 10/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0044 - mae: 0.0410\n",
      "Epoch 11/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0044 - mae: 0.0408\n",
      "Epoch 12/150\n",
      "2418010/2418010 [==============================] - 226s 93us/sample - loss: 0.0044 - mae: 0.0407\n",
      "Epoch 13/150\n",
      "2418010/2418010 [==============================] - 231s 95us/sample - loss: 0.0043 - mae: 0.0405\n",
      "Epoch 14/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0043 - mae: 0.0404\n",
      "Epoch 15/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0043 - mae: 0.0404\n",
      "Epoch 16/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0043 - mae: 0.0402\n",
      "Epoch 17/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0043 - mae: 0.0401\n",
      "Epoch 18/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0401\n",
      "Epoch 19/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0400\n",
      "Epoch 20/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0399\n",
      "Epoch 21/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0399\n",
      "Epoch 22/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0042 - mae: 0.0398\n",
      "Epoch 23/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0397\n",
      "Epoch 24/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0042 - mae: 0.0397\n",
      "Epoch 25/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0041 - mae: 0.0396\n",
      "Epoch 26/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0041 - mae: 0.0396\n",
      "Epoch 27/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0041 - mae: 0.0395\n",
      "Epoch 28/150\n",
      "2418010/2418010 [==============================] - 229s 95us/sample - loss: 0.0041 - mae: 0.0395\n",
      "Epoch 29/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0041 - mae: 0.0394\n",
      "Epoch 30/150\n",
      "2418010/2418010 [==============================] - 226s 94us/sample - loss: 0.0041 - mae: 0.0394\n",
      "Epoch 31/150\n",
      "2418010/2418010 [==============================] - 226s 94us/sample - loss: 0.0041 - mae: 0.0393\n",
      "Epoch 32/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0041 - mae: 0.0394\n",
      "Epoch 33/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0041 - mae: 0.0392\n",
      "Epoch 34/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0041 - mae: 0.0392\n",
      "Epoch 35/150\n",
      "2418010/2418010 [==============================] - 231s 95us/sample - loss: 0.0041 - mae: 0.0392\n",
      "Epoch 36/150\n",
      "2418010/2418010 [==============================] - 229s 95us/sample - loss: 0.0040 - mae: 0.0391\n",
      "Epoch 37/150\n",
      "2418010/2418010 [==============================] - 234s 97us/sample - loss: 0.0040 - mae: 0.0391\n",
      "Epoch 38/150\n",
      "2418010/2418010 [==============================] - 229s 95us/sample - loss: 0.0040 - mae: 0.0391\n",
      "Epoch 39/150\n",
      "2418010/2418010 [==============================] - 229s 95us/sample - loss: 0.0040 - mae: 0.0391\n",
      "Epoch 40/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0390\n",
      "Epoch 41/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0391\n",
      "Epoch 42/150\n",
      "2418010/2418010 [==============================] - 235s 97us/sample - loss: 0.0040 - mae: 0.0390\n",
      "Epoch 43/150\n",
      "2418010/2418010 [==============================] - 257s 106us/sample - loss: 0.0040 - mae: 0.0389\n",
      "Epoch 44/150\n",
      "2418010/2418010 [==============================] - 237s 98us/sample - loss: 0.0040 - mae: 0.0389\n",
      "Epoch 45/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0389\n",
      "Epoch 46/150\n",
      "2418010/2418010 [==============================] - 231s 95us/sample - loss: 0.0040 - mae: 0.0389\n",
      "Epoch 47/150\n",
      "2418010/2418010 [==============================] - 229s 95us/sample - loss: 0.0040 - mae: 0.0389\n",
      "Epoch 48/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 49/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 50/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 51/150\n",
      "2418010/2418010 [==============================] - 231s 96us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 52/150\n",
      "2418010/2418010 [==============================] - 230s 95us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 53/150\n",
      "2418010/2418010 [==============================] - 231s 95us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 54/150\n",
      "2418010/2418010 [==============================] - 240s 99us/sample - loss: 0.0040 - mae: 0.0387\n",
      "Epoch 55/150\n",
      "2418010/2418010 [==============================] - 267s 111us/sample - loss: 0.0040 - mae: 0.0388\n",
      "Epoch 56/150\n",
      "2418010/2418010 [==============================] - 258s 107us/sample - loss: 0.0040 - mae: 0.0387\n",
      "Epoch 57/150\n",
      "2418010/2418010 [==============================] - 256s 106us/sample - loss: 0.0040 - mae: 0.0387\n",
      "Epoch 58/150\n",
      "2418010/2418010 [==============================] - 243s 101us/sample - loss: 0.0040 - mae: 0.0387\n",
      "Epoch 59/150\n",
      "2418010/2418010 [==============================] - 275s 114us/sample - loss: 0.0040 - mae: 0.0387\n",
      "Epoch 60/150\n",
      "2418010/2418010 [==============================] - 274s 113us/sample - loss: 0.0039 - mae: 0.0387\n",
      "Epoch 61/150\n",
      "2418010/2418010 [==============================] - 284s 117us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 62/150\n",
      "2418010/2418010 [==============================] - 282s 117us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 63/150\n",
      "2418010/2418010 [==============================] - 267s 111us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 64/150\n",
      "2418010/2418010 [==============================] - 272s 112us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 65/150\n",
      "2418010/2418010 [==============================] - 261s 108us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 66/150\n",
      "2418010/2418010 [==============================] - 268s 111us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 67/150\n",
      "2418010/2418010 [==============================] - 252s 104us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 68/150\n",
      "2418010/2418010 [==============================] - 247s 102us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 69/150\n",
      "2418010/2418010 [==============================] - 259s 107us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 70/150\n",
      "2418010/2418010 [==============================] - 279s 115us/sample - loss: 0.0039 - mae: 0.0386\n",
      "Epoch 71/150\n",
      "2418010/2418010 [==============================] - 274s 113us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 72/150\n",
      "2418010/2418010 [==============================] - 260s 107us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 73/150\n",
      "2418010/2418010 [==============================] - 266s 110us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418010/2418010 [==============================] - 255s 106us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 75/150\n",
      "2418010/2418010 [==============================] - 249s 103us/sample - loss: 0.0039 - mae: 0.0385\n",
      "Epoch 76/150\n",
      "2418010/2418010 [==============================] - 255s 106us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 77/150\n",
      "2418010/2418010 [==============================] - 251s 104us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 78/150\n",
      "2418010/2418010 [==============================] - 255s 105us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 79/150\n",
      "2418010/2418010 [==============================] - 258s 107us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 80/150\n",
      "2418010/2418010 [==============================] - 259s 107us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 81/150\n",
      "2418010/2418010 [==============================] - 246s 102us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 82/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 83/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 84/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 85/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 86/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 87/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0384\n",
      "Epoch 88/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 89/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 90/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 91/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 92/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 93/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 94/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 95/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 96/150\n",
      "2418010/2418010 [==============================] - 224s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 97/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 98/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 99/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 100/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0383\n",
      "Epoch 101/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 102/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 103/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 104/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 105/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 106/150\n",
      "2418010/2418010 [==============================] - 221s 91us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 107/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 108/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 109/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 110/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 111/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 112/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 113/150\n",
      "2418010/2418010 [==============================] - 221s 91us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 114/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 115/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0381\n",
      "Epoch 116/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 117/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 118/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 119/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 120/150\n",
      "2418010/2418010 [==============================] - 227s 94us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 121/150\n",
      "2418010/2418010 [==============================] - 221s 92us/sample - loss: 0.0039 - mae: 0.0382\n",
      "Epoch 122/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 123/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 124/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 125/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 126/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0381\n",
      "Epoch 127/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 128/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 129/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 130/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 131/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 132/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 133/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 134/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 135/150\n",
      "2418010/2418010 [==============================] - 222s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 136/150\n",
      "2418010/2418010 [==============================] - 228s 94us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 137/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 138/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 139/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0379\n",
      "Epoch 140/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 141/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 142/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 143/150\n",
      "2418010/2418010 [==============================] - 224s 93us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 144/150\n",
      "2418010/2418010 [==============================] - 224s 92us/sample - loss: 0.0038 - mae: 0.0379\n",
      "Epoch 145/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 146/150\n",
      "2418010/2418010 [==============================] - 223s 92us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 147/150\n",
      "2418010/2418010 [==============================] - 225s 93us/sample - loss: 0.0038 - mae: 0.0379\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418010/2418010 [==============================] - 220s 91us/sample - loss: 0.0038 - mae: 0.0379\n",
      "Epoch 149/150\n",
      "2418010/2418010 [==============================] - 220s 91us/sample - loss: 0.0038 - mae: 0.0380\n",
      "Epoch 150/150\n",
      "2418010/2418010 [==============================] - 220s 91us/sample - loss: 0.0038 - mae: 0.0380\n"
     ]
    }
   ],
   "source": [
    "history = model_meter2.fit(X2, y2, epochs=150\n",
    "                           , batch_size=64\n",
    "#                          , verbose=0\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1135278 samples\n",
      "Epoch 1/200\n",
      "1135278/1135278 [==============================] - 102s 90us/sample - loss: 0.0180 - mae: 0.0907\n",
      "Epoch 2/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0132 - mae: 0.0752\n",
      "Epoch 3/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0126 - mae: 0.0719\n",
      "Epoch 4/200\n",
      "1135278/1135278 [==============================] - 103s 91us/sample - loss: 0.0122 - mae: 0.0701\n",
      "Epoch 5/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0120 - mae: 0.0691\n",
      "Epoch 6/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0117 - mae: 0.0681\n",
      "Epoch 7/200\n",
      "1135278/1135278 [==============================] - ETA: 0s - loss: 0.0116 - mae: 0.067 - 98s 87us/sample - loss: 0.0116 - mae: 0.0675\n",
      "Epoch 8/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0115 - mae: 0.0669\n",
      "Epoch 9/200\n",
      "1135278/1135278 [==============================] - 99s 88us/sample - loss: 0.0114 - mae: 0.0664\n",
      "Epoch 10/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0112 - mae: 0.0660\n",
      "Epoch 11/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0111 - mae: 0.0655\n",
      "Epoch 12/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0111 - mae: 0.0652\n",
      "Epoch 13/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0110 - mae: 0.0650\n",
      "Epoch 14/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0110 - mae: 0.0649\n",
      "Epoch 15/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0109 - mae: 0.0646\n",
      "Epoch 16/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0109 - mae: 0.0643\n",
      "Epoch 17/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0108 - mae: 0.0641\n",
      "Epoch 18/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0108 - mae: 0.0639\n",
      "Epoch 19/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0107 - mae: 0.0638\n",
      "Epoch 20/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0107 - mae: 0.0634\n",
      "Epoch 21/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0106 - mae: 0.0634\n",
      "Epoch 22/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0106 - mae: 0.0632\n",
      "Epoch 23/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0106 - mae: 0.0632\n",
      "Epoch 24/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0105 - mae: 0.0631\n",
      "Epoch 25/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0105 - mae: 0.0629\n",
      "Epoch 26/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0105 - mae: 0.0628\n",
      "Epoch 27/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0104 - mae: 0.0626\n",
      "Epoch 28/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0104 - mae: 0.0626\n",
      "Epoch 29/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0104 - mae: 0.0625\n",
      "Epoch 30/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0104 - mae: 0.0624\n",
      "Epoch 31/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0104 - mae: 0.0624\n",
      "Epoch 32/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0103 - mae: 0.0623\n",
      "Epoch 33/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0103 - mae: 0.0622\n",
      "Epoch 34/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0103 - mae: 0.0621\n",
      "Epoch 35/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0103 - mae: 0.0621\n",
      "Epoch 36/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0102 - mae: 0.0619\n",
      "Epoch 37/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0102 - mae: 0.0620\n",
      "Epoch 38/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0102 - mae: 0.0619\n",
      "Epoch 39/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0102 - mae: 0.0620\n",
      "Epoch 40/200\n",
      "1135278/1135278 [==============================] - 104s 92us/sample - loss: 0.0102 - mae: 0.0618\n",
      "Epoch 41/200\n",
      "1135278/1135278 [==============================] - 102s 90us/sample - loss: 0.0102 - mae: 0.0617\n",
      "Epoch 42/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0102 - mae: 0.0617\n",
      "Epoch 43/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0101 - mae: 0.0616\n",
      "Epoch 44/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0101 - mae: 0.0617\n",
      "Epoch 45/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0101 - mae: 0.0616\n",
      "Epoch 46/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0101 - mae: 0.0616\n",
      "Epoch 47/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0101 - mae: 0.0615\n",
      "Epoch 48/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0101 - mae: 0.0616\n",
      "Epoch 49/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0101 - mae: 0.0615\n",
      "Epoch 50/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0100 - mae: 0.0614\n",
      "Epoch 51/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0615\n",
      "Epoch 52/200\n",
      "1135278/1135278 [==============================] - 102s 89us/sample - loss: 0.0100 - mae: 0.0614\n",
      "Epoch 53/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0614\n",
      "Epoch 54/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0613\n",
      "Epoch 55/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0613\n",
      "Epoch 56/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0611\n",
      "Epoch 57/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0612\n",
      "Epoch 58/200\n",
      "1135278/1135278 [==============================] - 102s 90us/sample - loss: 0.0100 - mae: 0.0611\n",
      "Epoch 59/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0100 - mae: 0.0611\n",
      "Epoch 60/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0611\n",
      "Epoch 61/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0611\n",
      "Epoch 62/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 63/200\n",
      "1135278/1135278 [==============================] - 102s 90us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 64/200\n",
      "1135278/1135278 [==============================] - 100s 89us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 65/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 66/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 67/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 68/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 69/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0099 - mae: 0.0610\n",
      "Epoch 70/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 71/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0608\n",
      "Epoch 72/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0099 - mae: 0.0608\n",
      "Epoch 73/200\n",
      "1135278/1135278 [==============================] - 100s 89us/sample - loss: 0.0099 - mae: 0.0608\n",
      "Epoch 74/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0098 - mae: 0.0607\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 76/200\n",
      "1135278/1135278 [==============================] - 103s 90us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 77/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0099 - mae: 0.0609\n",
      "Epoch 78/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0607\n",
      "Epoch 79/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 80/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 81/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0098 - mae: 0.0607\n",
      "Epoch 82/200\n",
      "1135278/1135278 [==============================] - ETA: 0s - loss: 0.0098 - mae: 0.060 - 97s 85us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 83/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0607\n",
      "Epoch 84/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 85/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0607\n",
      "Epoch 86/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 87/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 88/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0098 - mae: 0.0605\n",
      "Epoch 89/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0605\n",
      "Epoch 90/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0098 - mae: 0.0605\n",
      "Epoch 91/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0605\n",
      "Epoch 92/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0097 - mae: 0.0605\n",
      "Epoch 93/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 94/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 95/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 96/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 97/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 98/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 99/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 100/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 101/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 102/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0604\n",
      "Epoch 103/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 104/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 105/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 106/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 107/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 108/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0602\n",
      "Epoch 109/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0602\n",
      "Epoch 110/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0097 - mae: 0.0602\n",
      "Epoch 111/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 112/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 113/200\n",
      "1135278/1135278 [==============================] - 103s 91us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 114/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 115/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 116/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 117/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 118/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 119/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 120/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 121/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 122/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 123/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 124/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 125/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 126/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 127/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 128/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 129/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 130/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 131/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 132/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 133/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 134/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 135/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 136/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 137/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 138/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 139/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 140/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 141/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0096 - mae: 0.0597\n",
      "Epoch 142/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 143/200\n",
      "1135278/1135278 [==============================] - ETA: 0s - loss: 0.0096 - mae: 0.059 - 98s 87us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 144/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 145/200\n",
      "1135278/1135278 [==============================] - 99s 88us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 146/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 147/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 148/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 150/200\n",
      "1135278/1135278 [==============================] - 99s 87us/sample - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 151/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 152/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 153/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 154/200\n",
      "1135278/1135278 [==============================] - 98s 87us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 155/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 156/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 157/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 158/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0095 - mae: 0.0598\n",
      "Epoch 159/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 160/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 161/200\n",
      "1135278/1135278 [==============================] - 97s 86us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 162/200\n",
      "1135278/1135278 [==============================] - 110s 97us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 163/200\n",
      "1135278/1135278 [==============================] - 111s 98us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 164/200\n",
      "1135278/1135278 [==============================] - 98s 86us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 165/200\n",
      "1135278/1135278 [==============================] - 118s 104us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 166/200\n",
      "1135278/1135278 [==============================] - 124s 109us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 167/200\n",
      "1135278/1135278 [==============================] - 110s 97us/sample - loss: 0.0095 - mae: 0.0598\n",
      "Epoch 168/200\n",
      "1135278/1135278 [==============================] - 101s 89us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 169/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 170/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 171/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 172/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 173/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 174/200\n",
      "1135278/1135278 [==============================] - 97s 85us/sample - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 175/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 176/200\n",
      "1135278/1135278 [==============================] - 95s 83us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 177/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 178/200\n",
      "1135278/1135278 [==============================] - 96s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 179/200\n",
      "1135278/1135278 [==============================] - 95s 83us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 180/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 181/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 182/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 183/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 184/200\n",
      "1135278/1135278 [==============================] - 96s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 185/200\n",
      "1135278/1135278 [==============================] - 96s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 186/200\n",
      "1135278/1135278 [==============================] - 100s 88us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 187/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 188/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 189/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 190/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 191/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 192/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 193/200\n",
      "1135278/1135278 [==============================] - 95s 83us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 194/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 195/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 196/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 197/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 198/200\n",
      "1135278/1135278 [==============================] - 96s 84us/sample - loss: 0.0094 - mae: 0.0593\n",
      "Epoch 199/200\n",
      "1135278/1135278 [==============================] - 95s 84us/sample - loss: 0.0095 - mae: 0.0594\n",
      "Epoch 200/200\n",
      "1135278/1135278 [==============================] - 96s 85us/sample - loss: 0.0095 - mae: 0.0594\n"
     ]
    }
   ],
   "source": [
    "history = model_meter3.fit(X3, y3, epochs=200\n",
    "                           , batch_size=64\n",
    "#                          , verbose=0\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meter1.save('model_meter1.h5')\n",
    "model_meter2.save('model_meter2.h5')\n",
    "model_meter3.save('model_meter3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strat_train_set0', 1192.5961570739746),\n",
       " ('strat_train_set1', 432.0467233657837),\n",
       " ('strat_train_set2', 279.02530097961426),\n",
       " ('strat_test_set0', 132.51079273223877),\n",
       " ('strat_train_set3', 131.0049648284912),\n",
       " ('strat_test_set1', 48.00521183013916),\n",
       " ('strat_test_set2', 31.002857208251953),\n",
       " ('strat_test_set3', 14.556242942810059),\n",
       " ('train_index', 8.661575317382812),\n",
       " ('test_index', 0.9624862670898438),\n",
       " ('LabelEncoder', 0.001007080078125),\n",
       " ('StratifiedShuffleSplit', 0.001007080078125),\n",
       " ('MinMaxScaler', 0.00084686279296875),\n",
       " ('RobustScaler', 0.00084686279296875),\n",
       " ('build_model', 0.00012969970703125),\n",
       " ('reduce_mem_usage', 0.00012969970703125),\n",
       " ('X0', 0.0001068115234375),\n",
       " ('X0_test', 0.0001068115234375),\n",
       " ('X1', 0.0001068115234375),\n",
       " ('X1_test', 0.0001068115234375),\n",
       " ('X2', 0.0001068115234375),\n",
       " ('X2_test', 0.0001068115234375),\n",
       " ('X3', 0.0001068115234375),\n",
       " ('X3_test', 0.0001068115234375),\n",
       " ('y0', 9.1552734375e-05),\n",
       " ('y0_test', 9.1552734375e-05),\n",
       " ('y1', 9.1552734375e-05),\n",
       " ('y1_test', 9.1552734375e-05),\n",
       " ('y2', 9.1552734375e-05),\n",
       " ('y2_test', 9.1552734375e-05),\n",
       " ('y3', 9.1552734375e-05),\n",
       " ('y3_test', 9.1552734375e-05),\n",
       " ('np', 7.62939453125e-05),\n",
       " ('pd', 7.62939453125e-05),\n",
       " ('plt', 7.62939453125e-05),\n",
       " ('sns', 7.62939453125e-05),\n",
       " ('tf', 7.62939453125e-05),\n",
       " ('history', 5.340576171875e-05),\n",
       " ('le', 5.340576171875e-05),\n",
       " ('mm_0', 5.340576171875e-05),\n",
       " ('mm_1', 5.340576171875e-05),\n",
       " ('mm_2', 5.340576171875e-05),\n",
       " ('mm_3', 5.340576171875e-05),\n",
       " ('model_meter0', 5.340576171875e-05),\n",
       " ('model_meter1', 5.340576171875e-05),\n",
       " ('model_meter2', 5.340576171875e-05),\n",
       " ('model_meter3', 5.340576171875e-05),\n",
       " ('rob_0', 5.340576171875e-05),\n",
       " ('rob_1', 5.340576171875e-05),\n",
       " ('rob_2', 5.340576171875e-05),\n",
       " ('rob_3', 5.340576171875e-05),\n",
       " ('split', 5.340576171875e-05)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## list memory taken of objects\n",
    "import sys\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x)) / 1024**2) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del strat_train_set0, strat_train_set1,strat_train_set2, strat_train_set3, strat_test_set0, strat_test_set1, strat_test_set2, strat_test_set3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict the submit sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_0 = pickle.load(open('rob_0.pkl', 'rb'))\n",
    "mm_0 = pickle.load(open('mm_0.pkl', 'rb'))\n",
    "rob_1 = pickle.load(open('rob_1.pkl', 'rb'))\n",
    "mm_1 = pickle.load(open('mm_1.pkl', 'rb'))\n",
    "rob_2 = pickle.load(open('rob_2.pkl', 'rb'))\n",
    "mm_2 = pickle.load(open('mm_2.pkl', 'rb'))\n",
    "rob_3 = pickle.load(open('rob_3.pkl', 'rb'))\n",
    "mm_3 = pickle.load(open('mm_3.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict submit set with meter 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 3399.69 Mb to 991.58 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "# read data from file:\n",
    "submit_set0 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/test_set0.csv')\n",
    "submit_set0 = reduce_mem_usage(submit_set0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>sealev</th>\n",
       "      <th>dewtemp</th>\n",
       "      <th>windsp</th>\n",
       "      <th>North</th>\n",
       "      <th>West</th>\n",
       "      <th>South</th>\n",
       "      <th>nowind</th>\n",
       "      <th>dewair</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.649414</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>0.583008</td>\n",
       "      <td>0.655762</td>\n",
       "      <td>0.774902</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>0.590820</td>\n",
       "      <td>0.660645</td>\n",
       "      <td>0.782715</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755755</td>\n",
       "      <td>15</td>\n",
       "      <td>1448</td>\n",
       "      <td>6</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>2018-12-31 19:00:00</td>\n",
       "      <td>0.416992</td>\n",
       "      <td>0.611816</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.318115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41497570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755756</td>\n",
       "      <td>15</td>\n",
       "      <td>1448</td>\n",
       "      <td>6</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41497820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755757</td>\n",
       "      <td>15</td>\n",
       "      <td>1448</td>\n",
       "      <td>6</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>2018-12-31 21:00:00</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.598145</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.256104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41498070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755758</td>\n",
       "      <td>15</td>\n",
       "      <td>1448</td>\n",
       "      <td>6</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>0.410645</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.603027</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41498320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755759</td>\n",
       "      <td>15</td>\n",
       "      <td>1448</td>\n",
       "      <td>6</td>\n",
       "      <td>0.105164</td>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>0.416992</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>0.603027</td>\n",
       "      <td>0.210693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41498570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24755760 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          site_id  building_id  primary_use  square_feet            timestamp  \\\n",
       "0               0            0            0     0.008171  2017-01-01 00:00:00   \n",
       "1               0            0            0     0.008171  2017-01-01 01:00:00   \n",
       "2               0            0            0     0.008171  2017-01-01 02:00:00   \n",
       "3               0            0            0     0.008171  2017-01-01 03:00:00   \n",
       "4               0            0            0     0.008171  2017-01-01 04:00:00   \n",
       "...           ...          ...          ...          ...                  ...   \n",
       "24755755       15         1448            6     0.105164  2018-12-31 19:00:00   \n",
       "24755756       15         1448            6     0.105164  2018-12-31 20:00:00   \n",
       "24755757       15         1448            6     0.105164  2018-12-31 21:00:00   \n",
       "24755758       15         1448            6     0.105164  2018-12-31 22:00:00   \n",
       "24755759       15         1448            6     0.105164  2018-12-31 23:00:00   \n",
       "\n",
       "           airtemp    sealev   dewtemp    windsp  North  West  South  nowind  \\\n",
       "0         0.604980  0.649414  0.756836  0.148804    1.0   0.0    0.0     0.0   \n",
       "1         0.604980  0.656738  0.774902  0.128052    1.0   0.0    0.0     0.0   \n",
       "2         0.583008  0.655762  0.774902  0.128052    0.0   0.0    1.0     0.0   \n",
       "3         0.597168  0.659180  0.782715  0.128052    0.0   0.0    1.0     0.0   \n",
       "4         0.590820  0.660645  0.782715  0.107422    1.0   0.0    0.0     0.0   \n",
       "...            ...       ...       ...       ...    ...   ...    ...     ...   \n",
       "24755755  0.416992  0.611816  0.594727  0.318115    0.0   0.0    1.0     0.0   \n",
       "24755756  0.410645  0.605469  0.584961  0.210693    0.0   0.0    1.0     0.0   \n",
       "24755757  0.410645  0.598145  0.594727  0.256104    0.0   0.0    1.0     0.0   \n",
       "24755758  0.410645  0.584961  0.603027  0.210693    0.0   0.0    1.0     0.0   \n",
       "24755759  0.416992  0.567871  0.603027  0.210693    0.0   0.0    1.0     0.0   \n",
       "\n",
       "            dewair  month  weekday  hour    row_id  \n",
       "0         0.110168    1.0      6.0   0.0         0  \n",
       "1         0.091248    1.0      6.0   1.0       129  \n",
       "2         0.061951    1.0      6.0   2.0       258  \n",
       "3         0.072266    1.0      6.0   3.0       387  \n",
       "4         0.063660    1.0      6.0   4.0       516  \n",
       "...            ...    ...      ...   ...       ...  \n",
       "24755755  0.032715    0.0      0.0  19.0  41497570  \n",
       "24755756  0.034424    0.0      0.0  20.0  41497820  \n",
       "24755757  0.024094    0.0      0.0  21.0  41498070  \n",
       "24755758  0.015488    0.0      0.0  22.0  41498320  \n",
       "24755759  0.024094    0.0      0.0  23.0  41498570  \n",
       "\n",
       "[24755760 rows x 18 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_set0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for submit_set0\n",
    "X_sub0 = [submit_set0.building_id.values, submit_set0.primary_use.values,\n",
    "          submit_set0.month.values, submit_set0.weekday.values, submit_set0.hour.values,\n",
    "          submit_set0.drop(['site_id','building_id','timestamp','dewair','row_id'], axis=1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_meter0 = tf.keras.models.load_model('model_meter0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict submit_set0\n",
    "submit_y0 = model_meter0.predict(X_sub0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y0 = pd.Series(submit_y0.reshape(-1,))\n",
    "submit_y0.name = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y0 = pd.concat([submit_set0.row_id,submit_y0], axis=1)\n",
    "submit_y0.columns = ['row_id','meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_transform for submit_y0\n",
    "submit_y0.meter_reading = np.exp(rob_0.inverse_transform(mm_0.inverse_transform(submit_y0.meter_reading.values.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.717548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>58.312996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>60.146324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>387</td>\n",
       "      <td>60.790489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>516</td>\n",
       "      <td>59.154659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755755</td>\n",
       "      <td>41497570</td>\n",
       "      <td>4.228437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755756</td>\n",
       "      <td>41497820</td>\n",
       "      <td>4.229010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755757</td>\n",
       "      <td>41498070</td>\n",
       "      <td>4.203444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755758</td>\n",
       "      <td>41498320</td>\n",
       "      <td>4.226560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755759</td>\n",
       "      <td>41498570</td>\n",
       "      <td>4.233212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24755760 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0      58.717548\n",
       "1              129      58.312996\n",
       "2              258      60.146324\n",
       "3              387      60.790489\n",
       "4              516      59.154659\n",
       "...            ...            ...\n",
       "24755755  41497570       4.228437\n",
       "24755756  41497820       4.229010\n",
       "24755757  41498070       4.203444\n",
       "24755758  41498320       4.226560\n",
       "24755759  41498570       4.233212\n",
       "\n",
       "[24755760 rows x 2 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply by 0.2931 to get to model inputs into kWh like the other sites, \n",
    "# and 3.4118 to get back to kBTU for scoring\n",
    "converted_meter0 = submit_y0[submit_set0.site_id ==0].meter_reading.mul(3.4118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          200.332532\n",
       "1          198.952279\n",
       "2          205.207229\n",
       "3          207.404991\n",
       "4          201.823867\n",
       "              ...    \n",
       "1839595    399.118831\n",
       "1839596    391.827160\n",
       "1839597    385.250246\n",
       "1839598    364.571284\n",
       "1839599    357.829392\n",
       "Name: meter_reading, Length: 1839600, dtype: float64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_meter0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raymond.guo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# submit_y0.update(converted_meter0)\n",
    "submit_y0.meter_reading[submit_set0.site_id ==0] = converted_meter0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.332535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>198.952286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>205.207230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>387</td>\n",
       "      <td>207.404984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>516</td>\n",
       "      <td>201.823868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755755</td>\n",
       "      <td>41497570</td>\n",
       "      <td>4.228437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755756</td>\n",
       "      <td>41497820</td>\n",
       "      <td>4.229010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755757</td>\n",
       "      <td>41498070</td>\n",
       "      <td>4.203444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755758</td>\n",
       "      <td>41498320</td>\n",
       "      <td>4.226560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24755759</td>\n",
       "      <td>41498570</td>\n",
       "      <td>4.233212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24755760 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     200.332535\n",
       "1              129     198.952286\n",
       "2              258     205.207230\n",
       "3              387     207.404984\n",
       "4              516     201.823868\n",
       "...            ...            ...\n",
       "24755755  41497570       4.228437\n",
       "24755756  41497820       4.229010\n",
       "24755757  41498070       4.203444\n",
       "24755758  41498320       4.226560\n",
       "24755759  41498570       4.233212\n",
       "\n",
       "[24755760 rows x 2 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y0.to_csv('C:/data/Kaggle_ASHRAE_energy/submit_y0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201257"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submit_set0, model_meter0, converted_meter0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict submit set with meter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 1198.19 Mb to 349.47 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "submit_set1 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/test_set1.csv')\n",
    "submit_set1 = reduce_mem_usage(submit_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub1 = [submit_set1.building_id.values, submit_set1.primary_use.values,\n",
    "          submit_set1.month.values, submit_set1.weekday.values, submit_set1.hour.values,\n",
    "          submit_set1.drop(['site_id','building_id','timestamp','dewair','row_id'], axis=1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meter1 = tf.keras.models.load_model('model_meter1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y1 = model_meter1.predict(X_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y1 = pd.Series(submit_y1.reshape(-1,))\n",
    "submit_y1 = pd.concat([submit_set1.row_id,submit_y1], axis=1)\n",
    "submit_y1.columns = ['row_id','meter_reading']\n",
    "submit_y1.meter_reading = np.exp(rob_1.inverse_transform(mm_1.inverse_transform(submit_y1.meter_reading.values.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1186.419556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1166.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>1247.665283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>395</td>\n",
       "      <td>1200.930298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>524</td>\n",
       "      <td>1361.159424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8724955</td>\n",
       "      <td>41497512</td>\n",
       "      <td>3.729261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8724956</td>\n",
       "      <td>41497762</td>\n",
       "      <td>3.680798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8724957</td>\n",
       "      <td>41498012</td>\n",
       "      <td>3.647092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8724958</td>\n",
       "      <td>41498262</td>\n",
       "      <td>3.638701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8724959</td>\n",
       "      <td>41498512</td>\n",
       "      <td>3.624163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8724960 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id  meter_reading\n",
       "0               8    1186.419556\n",
       "1             137    1166.770020\n",
       "2             266    1247.665283\n",
       "3             395    1200.930298\n",
       "4             524    1361.159424\n",
       "...           ...            ...\n",
       "8724955  41497512       3.729261\n",
       "8724956  41497762       3.680798\n",
       "8724957  41498012       3.647092\n",
       "8724958  41498262       3.638701\n",
       "8724959  41498512       3.624163\n",
       "\n",
       "[8724960 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y1.to_csv('C:/data/Kaggle_ASHRAE_energy/submit_y1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312284"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submit_set1, model_meter1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict submit set with meter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 779.55 Mb to 227.37 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "submit_set2 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/test_set2.csv')\n",
    "submit_set2 = reduce_mem_usage(submit_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub2 = [submit_set2.building_id.values, submit_set2.primary_use.values,\n",
    "          submit_set2.month.values, submit_set2.weekday.values, submit_set2.hour.values,\n",
    "          submit_set2.drop(['site_id','building_id','timestamp','dewair','row_id'], axis=1).values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meter2 = tf.keras.models.load_model('model_meter2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y2 = model_meter2.predict(X_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y2 = pd.Series(submit_y2.reshape(-1,))\n",
    "submit_y2 = pd.concat([submit_set2.row_id,submit_y2], axis=1)\n",
    "submit_y2.columns = ['row_id','meter_reading']\n",
    "submit_y2.meter_reading = np.exp(rob_2.inverse_transform(mm_2.inverse_transform(submit_y2.meter_reading.values.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41539346</td>\n",
       "      <td>1.258836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16340505</td>\n",
       "      <td>0.958289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16340663</td>\n",
       "      <td>1.027676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16340665</td>\n",
       "      <td>1.009106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16340745</td>\n",
       "      <td>1.019333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676475</td>\n",
       "      <td>41497555</td>\n",
       "      <td>70.612282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676476</td>\n",
       "      <td>41497805</td>\n",
       "      <td>71.344788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676477</td>\n",
       "      <td>41498055</td>\n",
       "      <td>71.467056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676478</td>\n",
       "      <td>41498305</td>\n",
       "      <td>69.184364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676479</td>\n",
       "      <td>41498555</td>\n",
       "      <td>61.568687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5676480 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id  meter_reading\n",
       "0        41539346       1.258836\n",
       "1        16340505       0.958289\n",
       "2        16340663       1.027676\n",
       "3        16340665       1.009106\n",
       "4        16340745       1.019333\n",
       "...           ...            ...\n",
       "5676475  41497555      70.612282\n",
       "5676476  41497805      71.344788\n",
       "5676477  41498055      71.467056\n",
       "5676478  41498305      69.184364\n",
       "5676479  41498555      61.568687\n",
       "\n",
       "[5676480 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y2.to_csv('C:/data/Kaggle_ASHRAE_energy/submit_y2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313092"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submit_set2\n",
    "del model_meter2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict submit set with meter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 348.87 Mb to 101.75 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "submit_set3 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/test_set3.csv')\n",
    "submit_set3 = reduce_mem_usage(submit_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub3 = [submit_set3.building_id.values, submit_set3.primary_use.values,\n",
    "          submit_set3.month.values, submit_set3.weekday.values, submit_set3.hour.values,\n",
    "          submit_set3.drop(['site_id','building_id','timestamp','dewair','row_id'], axis=1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meter3 = tf.keras.models.load_model('model_meter3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y3 = model_meter3.predict(X_sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y3 = pd.Series(submit_y3.reshape(-1,))\n",
    "submit_y3 = pd.concat([submit_set3.row_id,submit_y3], axis=1)\n",
    "submit_y3.columns = ['row_id','meter_reading']\n",
    "submit_y3.meter_reading = np.exp(rob_3.inverse_transform(mm_3.inverse_transform(submit_y3.meter_reading.values.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2260082</td>\n",
       "      <td>2.029935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2260145</td>\n",
       "      <td>2.231497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2260208</td>\n",
       "      <td>2.155344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2260271</td>\n",
       "      <td>2.265119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2260334</td>\n",
       "      <td>2.289279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540395</td>\n",
       "      <td>41497337</td>\n",
       "      <td>10383.036133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540396</td>\n",
       "      <td>41497587</td>\n",
       "      <td>10282.456055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540397</td>\n",
       "      <td>41497837</td>\n",
       "      <td>10542.301758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540398</td>\n",
       "      <td>41498087</td>\n",
       "      <td>9473.473633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540399</td>\n",
       "      <td>41498337</td>\n",
       "      <td>8569.735352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2540400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id  meter_reading\n",
       "0         2260082       2.029935\n",
       "1         2260145       2.231497\n",
       "2         2260208       2.155344\n",
       "3         2260271       2.265119\n",
       "4         2260334       2.289279\n",
       "...           ...            ...\n",
       "2540395  41497337   10383.036133\n",
       "2540396  41497587   10282.456055\n",
       "2540397  41497837   10542.301758\n",
       "2540398  41498087    9473.473633\n",
       "2540399  41498337    8569.735352\n",
       "\n",
       "[2540400 rows x 2 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y3.to_csv('C:/data/Kaggle_ASHRAE_energy/submit_y3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131147"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submit_set3\n",
    "del model_meter3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased from 376.12 Mb to 188.06 Mb (50.0% reduction)\n",
      "Mem. usage decreased from 132.47 Mb to 66.23 Mb (50.0% reduction)\n",
      "Mem. usage decreased from 38.58 Mb to 14.47 Mb (62.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "submit_y0 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/submit_y0.csv')\n",
    "submit_y0 = reduce_mem_usage(submit_y0)\n",
    "submit_y1 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/submit_y1.csv')\n",
    "submit_y1 = reduce_mem_usage(submit_y1)\n",
    "submit_y2 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/submit_y2.csv')\n",
    "submit_y2 = reduce_mem_usage(submit_y2)\n",
    "submit_y3 = pd.read_csv('C:/data/Kaggle_ASHRAE_energy/submit_y3.csv')\n",
    "submit_y3 = reduce_mem_usage(submit_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge all y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y = pd.concat([submit_y0,submit_y1,submit_y2,submit_y3], axis=0)\n",
    "submit_y = submit_y.sort_values(by='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.332535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17520</td>\n",
       "      <td>1</td>\n",
       "      <td>87.682877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35040</td>\n",
       "      <td>2</td>\n",
       "      <td>11.218434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52560</td>\n",
       "      <td>3</td>\n",
       "      <td>346.982910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70080</td>\n",
       "      <td>4</td>\n",
       "      <td>1671.388550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24679999</td>\n",
       "      <td>41697595</td>\n",
       "      <td>6.968567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24697519</td>\n",
       "      <td>41697596</td>\n",
       "      <td>5.823538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24715039</td>\n",
       "      <td>41697597</td>\n",
       "      <td>6.284033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24732559</td>\n",
       "      <td>41697598</td>\n",
       "      <td>173.554184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24750079</td>\n",
       "      <td>41697599</td>\n",
       "      <td>5.216142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     200.332535\n",
       "17520            1      87.682877\n",
       "35040            2      11.218434\n",
       "52560            3     346.982910\n",
       "70080            4    1671.388550\n",
       "...            ...            ...\n",
       "24679999  41697595       6.968567\n",
       "24697519  41697596       5.823538\n",
       "24715039  41697597       6.284033\n",
       "24732559  41697598     173.554184\n",
       "24750079  41697599       5.216142\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_y.to_csv('C:/data/Kaggle_ASHRAE_energy/submit_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes to debug the network when I got all nan output . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.15938824, -0.1609597 ,  0.13235152, ..., -0.10105675,\n",
       "         -0.11359914,  0.16553003]],\n",
       "\n",
       "       [[-0.74472386,  0.06896221, -0.7420141 , ..., -0.15583813,\n",
       "          0.8708445 , -0.24297723]],\n",
       "\n",
       "       [[-0.6348404 , -0.4213335 , -0.18732052, ..., -0.3587221 ,\n",
       "         -0.3043011 , -0.33298835]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.05055657,  0.08206438,  0.09478991, ..., -0.02927877,\n",
       "          0.15266207,  0.09116147]],\n",
       "\n",
       "       [[ 0.09414857, -0.10052757, -0.04715184, ...,  0.0859695 ,\n",
       "          0.29390404,  0.00264081]],\n",
       "\n",
       "       [[ 0.06126491, -0.48060998,  0.0963463 , ..., -0.0093626 ,\n",
       "         -0.02631511, -0.1163187 ]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the output of embedding layer, all nans\n",
    "building_id_emb1 = tf.keras.Model(inputs = model1.input,\n",
    "                                outputs = model1.get_layer('building_id_emb').output)\n",
    "building_id_output = building_id_emb1.predict(X)\n",
    "building_id_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the output of embedding layer, all nans\n",
    "building_id_emb = tf.keras.Model(inputs = model1.input,\n",
    "                                outputs = model1.get_layer('building_id_emb').output)\n",
    "building_id_output = building_id_emb.predict(X)\n",
    "building_id_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9189087, 1, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_id_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1300.],\n",
       "       [ 197.],\n",
       "       [ 138.],\n",
       "       ...,\n",
       "       [1049.],\n",
       "       [ 897.],\n",
       "       [  26.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the output of input layer\n",
    "input_building_id = tf.keras.Model(inputs = model1.input,\n",
    "                                outputs = model1.get_layer('input_building_id').output)\n",
    "input_building_id_output = input_building_id.predict(X)\n",
    "input_building_id_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9189087, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_building_id_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id          False\n",
       "building_id      False\n",
       "0                False\n",
       "1                False\n",
       "2                False\n",
       "3                False\n",
       "4                False\n",
       "5                False\n",
       "6                False\n",
       "7                False\n",
       "8                False\n",
       "9                False\n",
       "10               False\n",
       "11               False\n",
       "12               False\n",
       "13               False\n",
       "14               False\n",
       "15               False\n",
       "timestamp        False\n",
       "airtemp          False\n",
       "sealev           False\n",
       "dewtemp          False\n",
       "windsp           False\n",
       "North            False\n",
       "West             False\n",
       "South            False\n",
       "nowind           False\n",
       "dewair            True\n",
       "meter_reading    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4037"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are nan in dewair, which cause all nan output from embedding layer, need to get rid of that, \n",
    "# but for now I just abandon that feature.\n",
    "np.sum(strat_train_set.dewair.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
